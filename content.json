{"meta":{"title":"CY","subtitle":"","description":"CY的博客","author":"CY","url":"https://yao-chen-ecnu.github.io","root":"/"},"pages":[{"title":"404 Not Found：该页无法显示","date":"2021-03-15T08:24:55.051Z","updated":"2021-03-15T08:24:55.051Z","comments":false,"path":"/404.html","permalink":"https://yao-chen-ecnu.github.io/404.html","excerpt":"","text":""},{"title":"关于","date":"2021-03-15T08:24:55.051Z","updated":"2021-03-15T08:24:55.051Z","comments":false,"path":"about/index.html","permalink":"https://yao-chen-ecnu.github.io/about/index.html","excerpt":"","text":"个人详细介绍"},{"title":"书单","date":"2021-03-15T08:24:55.051Z","updated":"2021-03-15T08:24:55.051Z","comments":false,"path":"books/index.html","permalink":"https://yao-chen-ecnu.github.io/books/index.html","excerpt":"","text":""},{"title":"分类","date":"2021-03-21T06:28:01.744Z","updated":"2021-03-15T08:24:55.056Z","comments":false,"path":"categories/index.html","permalink":"https://yao-chen-ecnu.github.io/categories/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2021-03-15T08:24:55.056Z","updated":"2021-03-15T08:24:55.056Z","comments":true,"path":"links/index.html","permalink":"https://yao-chen-ecnu.github.io/links/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2021-03-15T08:24:55.056Z","updated":"2021-03-15T08:24:55.056Z","comments":false,"path":"repository/index.html","permalink":"https://yao-chen-ecnu.github.io/repository/index.html","excerpt":"","text":""},{"title":"标签","date":"2021-03-15T08:24:55.056Z","updated":"2021-03-15T08:24:55.056Z","comments":false,"path":"tags/index.html","permalink":"https://yao-chen-ecnu.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"知识蒸馏","slug":"知识蒸馏","date":"2021-04-21T02:54:58.228Z","updated":"2021-04-22T07:10:42.155Z","comments":true,"path":"2021/04/21/知识蒸馏/","link":"","permalink":"https://yao-chen-ecnu.github.io/2021/04/21/%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F/","excerpt":"","text":"知识蒸馏 知识蒸馏通常用于模型压缩，用一个已经训练好的模型A去“教”另外一个模型B。两个模型称为老师-学生模型。 通常模型A比模型B更强。在模型A的帮助下，模型B可以突破自我，学的更好。 Loss_Function_in_PyTorch softmax：输出是概率分布，(0,1) log_softmax：对sofmax取log，结果为负数 NLLLoss：输入：log_softmax，target，结果为正 CrossEntropy（交叉熵） 如上图所示，教师网络（左侧）的预测输出除以温度参数（Temperature）之后、再做softmax变换，可以获得软化的概率分布（软目标或软标签），数值介于0~1之间，取值分布较为缓和。 Temperature数值越大，分布越缓和；而Temperature数值减小，容易放大错误分类的概率，引入不必要的噪声。针对较困难的分类或检测任务，Temperature通常取1，确保教师网络中正确预测的贡献。 硬目标则是样本的真实标注，可以用one-hot矢量表示。 total loss设计为软目标与硬目标所对应的交叉熵的加权平均（表示为KD loss与CE loss），其中软目标交叉熵的加权系数越大，表明迁移诱导越依赖教师网络的贡献，这对训练初期阶段是很有必要的，有助于让学生网络更轻松的鉴别简单样本，但训练后期需要适当减小软目标的比重，让真实标注帮助鉴别困难样本。 另外，教师网络的推理性能通常要优于学生网络，而模型容量则无具体限制，且教师网络推理精度越高，越有利于学生网络的学习。","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://yao-chen-ecnu.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"联邦学习","slug":"联邦学习","permalink":"https://yao-chen-ecnu.github.io/tags/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"}]},{"title":"论文阅读总结","slug":"论文阅读总结","date":"2021-04-20T02:25:20.737Z","updated":"2021-04-22T07:15:51.578Z","comments":true,"path":"2021/04/20/论文阅读总结/","link":"","permalink":"https://yao-chen-ecnu.github.io/2021/04/20/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E6%80%BB%E7%BB%93/","excerpt":"","text":"论文阅读总结 1、Biscotti: A Blockchain System for Private and Secure Federated Learning 摘要 联合学习是支持安全多方机器学习(ML)的最新技术:数据保存在所有者的设备上，模型的更新通过安全协议进行聚合。然而，这个过程假设一个可信的集中式基础设施来进行协调，并且客户端必须相信中央服务不使用客户端数据的副产品。除此之外，一组恶意客户端还可能通过执行中毒攻击来损害模型的性能。作为回应，我们提出了Biscotti:一种完全分散的对等(P2P)多方消息传递方法，它使用区块链和加密原语来协调对等客户端之间的隐私保护消息传递过程。我们的评估表明，Biscotti是可扩展的、容错的，并且能够抵御已知的攻击。例如，当系统中存在30%的对手时，Biscotti能够保护单个客户端更新的隐私，并保持全局模型的大规模性能。 关键技术 运用Multi-Krum进行模型验证，防御毒化攻击 运用差分隐私保护信息不泄露 秘密共享进行安全聚合 随机验证函数和一致性哈希实现POF共识 多项式承诺 2、A Blockchain-based Decentralized Federated Learning Framework with Committee Consensus 摘要 联邦学习已经被广泛研究并应用于各种场景。在移动计算场景中，联合学习保护用户不暴露他们的私有数据，同时协作地为各种现实世界的应用程序训练全局模型。然而，由于恶意客户端或中央服务器不断攻击全局模型或用户隐私数据，联邦学习的安全性日益受到质疑。为了解决这些安全问题，我们提出了一个基于区块链的分布式联邦学习框架，即一个基于区块链的具有委员会共识的联邦学习框架。该框架将区块链用于全局模型存储和本地模型更新交换。为了实现提出的BFLC，我们还设计了一种创新的委员会共识机制，可以有效减少共识计算量，减少恶意攻击。然后我们讨论了BFLC的可扩展性，包括理论安全性、存储优化和激励。最后，我们使用真实数据集进行了实验，以验证BFLC框架的有效性。 3、Poster: A Reliable and Accountable Privacy-Preserving Federated Learning Framework using the Blockchain 摘要 联合学习有望支持涉及大数据集、大规模分布式数据所有者和不可靠网络连接的协作学习应用。为了保护数据隐私，现有的FL方法采用(k，n)-门限秘密共享方案，基于对客户端的半诚实假设，在本地模型更新交换中实现安全多方计算，以增加数据大小为代价处理随机客户端退出。这些方法对客户采用半诚实的假设，因此容易受到恶意客户的攻击。在这项工作中，我们提出了一个基于区块链隐私保护的联合学习框架，该框架利用了区块链的不变性和分散信任属性来提供模型更新的起源。我们基于BC的PPFL的概念验证实现证明了它对于联邦环境中本地模型更新的安全聚合是实用的。 关键技术 代理重加密 4、GFL: A Decentralized Federated Learning Framework Based On Blockchain 摘要 联合学习是一个快速发展的领域，已经提出了许多集中式和分散式的联合学习框架。然而，在恶意节点攻击下，如何提高通信性能、保持安全性和健壮性是当前FL框架面临的巨大挑战。在本文中，我们提出了Galaxy Federated Learning Framework(GFL)，一个基于区块链的分布式学习框架。**GFL引入了一致性哈希算法来提高通信性能，并提出了一种新的环分散算法(RDFL)来提高分布式的FL性能和带宽利用率。此外，GFL引入了星际文件系统(IPFS)和区块链，以进一步提高通信效率和FL安全性。**我们的实验表明，在恶意节点和非独立同分布(非IID)数据集的数据中毒情况下，GFL改进了通信性能和分布式FL性能。 关键技术 一致性哈希、知识蒸馏、环分散算法（RDFL）、IPFS","categories":[{"name":"区块链+联邦学习论文阅读笔记","slug":"区块链-联邦学习论文阅读笔记","permalink":"https://yao-chen-ecnu.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE-%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"区块链+联邦学习","slug":"区块链-联邦学习","permalink":"https://yao-chen-ecnu.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE-%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"}]},{"title":"A Reliable and Accountable Privacy-Preserving Federated Learning Framework using the Blockchain","slug":"Poster  A Reliable and Accountable Privacy-Preserving Federated Learning Framework using the Blockchain","date":"2021-04-19T13:00:42.432Z","updated":"2021-04-22T07:09:09.145Z","comments":true,"path":"2021/04/19/Poster  A Reliable and Accountable Privacy-Preserving Federated Learning Framework using the Blockchain/","link":"","permalink":"https://yao-chen-ecnu.github.io/2021/04/19/Poster%20%20A%20Reliable%20and%20Accountable%20Privacy-Preserving%20Federated%20Learning%20Framework%20using%20the%20Blockchain/","excerpt":"","text":"摘要 联合学习有望支持涉及大数据集、大规模分布式数据所有者和不可靠网络连接的协作学习应用。为了保护数据隐私，现有的FL方法采用(k，n)-门限秘密共享方案，基于对客户端的半诚实假设，在本地模型更新交换中实现安全多方计算，以增加数据大小为代价处理随机客户端退出。这些方法对客户采用半诚实的假设，因此容易受到恶意客户的攻击。在这项工作中，我们提出了一个基于区块链隐私保护的联合学习框架，该框架利用了区块链的不变性和分散信任属性来提供模型更新的起源。我们基于BC的PPFL的概念验证实现证明了它对于联邦环境中本地模型更新的安全聚合是实用的。 引言 早期的FL设计假设中间结果，如随机梯度下降的参数更新，包含的信息比原始训练数据少[6]。因此，短暂的更新经常被暴露。然而，这些梯度可能会泄漏本地数据项的重要信息，尤其是当诸如数据结构的元数据可用时。为了解决这个问题，最近已经提出了几种用于FL的安全聚合算法[2，3]，利用秘密共享和差分隐私技术。然而，这些方法假设参与客户的松散联盟，这些客户可能加入或不加入学习任务，因此遭受随机客户退出。[3]提出采用(k，n)-门限秘密共享来提高对退出的鲁棒性。事实上，这些方案的安全保障植根于对客户的半诚实假设，即假设客户不得提交“假”更新，也不得相互勾结操纵学习过程或结果。。此外，几乎所有关于FL的现有工作都明确或隐含地采用简单的激励模型，该模型假设客户自愿参与协作学习，以他们的本地模型更新和计算资源换取改进的全局模型。这种扁平激励模型忽略了这样一个事实，即具有不同数据大小和计算能力的客户端在全局优化任务中做出不同的贡献，并且应该得到不同的奖励。 本文的主要贡献： 在这项工作中，我们提出了一个基于区块链隐私保护的联合学习框架。如图1所示，区块链互连了前端组件，如服务器、客户端和聚合器。它使用分布式交易分类账来记录关于前线任务、参与客户、本地和全球模型更新等的信息流。，在组件中。不可变分类帐通过跟踪每个FL任务中的数据流来支持数据起源，并提供了一个良好的信任基础来构建现有FL方法缺乏的验证机制。有了这样的验证机制，我们可以进一步将半诚实客户端假设扩展到更现实的恶意客户端假设，在这种假设下，一个客户端可以退出，提交虚假的本地更新，或者与其他恶意客户端串通。此外，利用分布式分类帐，服务器以及FL任务中的其他感兴趣的实体(例如，客户端和聚合器)可以跟踪每个客户端对全局优化的学习模型的贡献，这使得基于贡献的激励机制成为可能。在此基础上，我们可以进一步引入改进模型所有权的溢价，并相应地奖励矿工。 框架设计 1、联邦学习模型： 联邦平均模型 基于BC的PPFL的主要隐私目标是(a)保护本地数据私有；(b)保护本地数据不受服务器的影响，不将个别本地模型更新泄露给服务器；以及©保护本地和全局模型更新不受无关的内部(即聚合器、矿工)和外部实体的影响。同时，安全目标是确保(a)来自承诺客户的本地模型更新的机密性和完整性，以及(b)模型更新的来源。 2、架构设计 为了实现安全和隐私保护目标，我们提出了一个基于业务连续性的PPFL框架，它由五个组件组成，如图1所示。对于FL任务，服务器首先通告任务规范，例如应用程序的类型(例如，击键或活动预测)、设备的类型、训练数据的类型和格式(例如，陀螺仪或运动传感器数据、浮点格式)、学习模型的类型(例如，CNN)、计算要求(例如，学习速率)和任务设置(例如，聚合器、所需客户端的数量、批量大小等)。) 在任务事务中。愿意加入任务的客户端向聚合器注册，然后聚合器为所有提交的客户端创建一个提交事务。最后，矿工将所有交易记录到分类账中。 在FL任务期间，服务器首先与所有提交的客户端共享初始模型。为了模型隐私，这个初始模型在保护模式下共享。然后，客户端根据其本地训练数据计算本地模型更新，并将更新后的模型参数上传到聚合器。聚合器在同一批中收到的所有更新将被打包到本地更新事务中，并在矿工的帮助下记录到分类帐中。 3、出块 基于BC的PPFL依赖于三个构建块来提供FL中的数据隐私和出处 同态加密和代理重加密 现有的大多数隐私保护联合学习方法都采用秘密共享方案来实现安全多方计算，这种方法存在随机客户端退出的问题。为了解决这个问题，我们采用了由克莱姆和肖普[4]提出的具有两个陷门函数的Paillier密码系统的变体，以在模型交换期间保护局部模型 在我们的设计中，服务器为每个任务生成一对公共和私有任务密钥，并将公共任务密钥包含在任务规范中，而任务中涉及的每个聚合器生成一对公共和私有批处理密钥，并将公共批处理密钥分发到每个提交的客户端。任务密钥和批密钥以这样的形式构造，即批密钥是相应任务密钥的转换密钥，以支持代理重加密。因此，服务器不能直接恢复记录在分类帐中的单个本地更新，而是仅在聚合器聚合更新并用转换密钥重新加密后恢复聚合值。 区块链 值得注意的是，对于大型数据集上的大型模型更新，我们可以将加密的模型更新存储在分布式数据库中，如IPFS [1]，并且只记录区块链的地址。 验证 验证器可以批量检索客户端的所有更新，生成排除来自可疑客户端的输入的集合，并且比较验证前后全局模型的性能。在初步实验中，我们实现了基本验证功能，其中服务器充当验证器，在每轮恢复聚合后评估梯度。它使用损失函数比较更新后的全局模型与该轮初始模型的性能。 4、实现与评估 在Python中开发了Paillier密码系统的变体，以实现同态加密和代理重加密 区块链基于以太坊和truffle框架 使用PyTorch实现深度学习训练 我们使用简单的两层神经网络构建了二进制分类器，并使用来自UCI机器学习库的乳腺癌数据集作为训练数据。数据集有569个样本和30个特征。对于我们框架中使用的所有三种密码系统，我们生成了默认长度为2048位的公钥和私钥对。 我们在亚马逊EC2 t2.micro实例上运行了区块链，该实例具有1千兆内存和3.3千兆赫英特尔可扩展处理器。对于服务器、聚合器和客户端节点，我们采用了两种设置:在设置一中，我们在2 GHz英特尔酷睿i5处理器和3 GiB内存的笔记本电脑上运行所有三种类型的节点，它们可以从这里与亚马逊EC2上实现的区块链进行交互；在设置二中，我们也在亚马逊EC2实例上运行它们，这最小化了通信延迟，因为所有实例都在同一个云平台上。未来，我们将通过在多个云平台上部署不同的节点，进一步研究我们框架的可扩展性和通信延迟。 评估 我们首先在10个客户中随机划分训练数据，每个客户有50个来自IID划分数据的例子。然后，我们测量了不同FL操作的执行时间 我们重复了四次模型训练，并计算了单次迭代的平均执行时间，如表1所示。显然，在这两种设置下，在所有FL操作中，聚集梯度并将结果写入区块链是计算成本最高的操作。每次迭代的平均执行时间是所有FL操作的总和，在设置一和设置二中分别是1.62和1.27秒。这两种设置之间的差异表明了向区块链读写所引入的通信成本。 因此，我们将客户机批处理大小增加到20、30和40，并测量了执行时间。平均执行时间从10个客户端的1.62秒分别增加到20、30和40个客户端的1.73、2.36和2.43秒。这表明客户端数量的增加导致协议执行时间的次线性增加。 结论 在未来，我们将探索联合优化，在客户端的每个训练阶段结合小批量，并增加多客户端并行性，以实现目标测试集的准确性。我们还将考虑非IID分区数据，并根据客户的贡献调查奖励客户的激励计划。","categories":[{"name":"区块链+联邦学习论文阅读笔记","slug":"区块链-联邦学习论文阅读笔记","permalink":"https://yao-chen-ecnu.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE-%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"区块链+联邦学习","slug":"区块链-联邦学习","permalink":"https://yao-chen-ecnu.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE-%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"}]},{"title":"GFL A Decentralized Federated Learning Framework Based On Blockchain","slug":"GFL A Decentralized Federated Learning Framework Based On Blockchain","date":"2021-04-19T12:22:21.792Z","updated":"2021-04-22T07:01:50.420Z","comments":true,"path":"2021/04/19/GFL A Decentralized Federated Learning Framework Based On Blockchain/","link":"","permalink":"https://yao-chen-ecnu.github.io/2021/04/19/GFL%20A%20Decentralized%20Federated%20Learning%20Framework%20Based%20On%20Blockchain/","excerpt":"","text":"摘要 联合学习是一个快速发展的领域，已经提出了许多集中式和分散式的联合学习框架。然而，在恶意节点攻击下，如何提高通信性能、保持安全性和健壮性是当前FL框架面临的巨大挑战。在本文中，我们提出了Galaxy Federated Learning Framework(GFL)，一个基于区块链的分布式学习框架。**GFL引入了一致性哈希算法来提高通信性能，并提出了一种新的环分散算法(RDFL)来提高分布式的FL性能和带宽利用率。此外，GFL引入了星际文件系统(IPFS)和区块链，以进一步提高通信效率和FL安全性。**我们的实验表明，在恶意节点和非独立同分布(非IID)数据集的数据中毒情况下，GFL改进了通信性能和分布式FL性能。 引言 主要贡献： 本文设计了一种新的数据节点拓扑机制，采用了一致哈希算法。该机制能够显著降低通信压力，提高拓扑稳定性。 一种新的环形分散联邦学习(RDFL)算法，旨在提高带宽利用率以及分布式联邦学习的性能 为了提高分散式FL框架的通信性能和安全性，我们引入了IPFS技术来降低系统通信压力，引入了区块链技术来提高FL安全性。 框架介绍 1、环形分布式FL拓扑 一组nnn个数据节点，其中有mmm个为诚实可信任节点，其余n−mn-mn−m个为不可信任节点。这nnn个数据表示为DP1,DP2,DP3,...,DPn{DP_1,DP_2,DP_3,...,DP_n}DP1​,DP2​,DP3​,...,DPn​。GFL利用一致哈希算法来构建n个数据节点的环形拓扑。 一致性给哈希值Hk=Hash⁡(DPkip)⊆[0,232−1],DPkipH_{k}=\\operatorname{Hash}\\left(D P_{k}^{i p}\\right) \\subseteq\\left[0,2^{32}-1\\right], D P_{k}^{i p}Hk​=Hash(DPkip​)⊆[0,232−1],DPkip​ 代表了DPKDP_KDPK​的ip，k⊆[i,n]k\\subseteq[i,n]k⊆[i,n] 根据一致性哈希指，数据节点分布在环上，取值范围为[0,232−1][0,2^{32}-1][0,232−1] 不可信数据节点将把本地模型以顺时针方向发送到在环形拓扑上找到的最近的可信数据节点。图1显示了由一致哈希算法构建的环形拓扑。绿色数据节点代表可信数据节点，灰色数据节点代表不可信数据节点。根据顺时针原则，不可信数据节点DP2DP_2DP2​和DP3DP_3DP3​向可信数据提供者DP4DP_4DP4​发送模型。不可信数据节点DP5DP_5DP5​将模型发送到最近的可信数据节点DPkDP_kDPk​。 借助一致哈希算法，不同的不可信数据节点向不同的可信节点发送模型，有效降低了可信节点的通信压力。为了使环上可信节点的分布更加均匀，GFL引入了虚拟可信节点进一步降低通信压力，图2显示了带有虚拟节点的环形拓扑。 带有红色虚线的绿色节点代表虚拟节点。DP1v1DP^{v1}_1DP1v1​是DP1DP_1DP1​的虚拟节点。如果不可信数据节点发现最近的可信节点是顺时针方向的虚拟节点，则直接将模型发送给该虚拟节点对应的可信节点。 为什么要添加这个虚拟节点呢？ 2、RDFL算法 基于一致哈希算法构造的环分散拓扑，GFL开始执行RDFL算法。可信节点遵循图3所示的RDFL算法过程。MKM_KMK​表示数据节点DPkDP_kDPk​的模型。rrr表示执行模型同步的回合数，mmm表示可信节点数。 在每次迭代中 每个数据节点加载全局模型用于局部训练，并沿顺时针方向同步其模型 利用知识蒸馏将可信节点拥有的其他模型的暗知识收敛到局部模型，并在可信节点之间同步局部模型 每个可信节点执行联邦平均算法，生成新的全局模型并开始下一次迭代。 具体每一步的执行 （1）训练和同步模型 每个数据节点DPkDP_kDPk​首先加载上一次迭代生成的全局模型GMGMGM进行局部训练，得到一个新的局部模型MkM_kMk​，然后不可信节点根据顺时针原理将局部模型发送给最近的可信节点。此外，可信节点同步模型，使得所有可信节点获得剩余可信节点的模型。为了提高可信节点之间的带宽利用率，RDFL算法在一致性哈希算法中引入了Ring-allreduce和顺时针原则来实现模型同步。 从图1中可以看出，在同步开始之前，可信节点DP4DP_4DP4​接收来自不可信节点DP2DP_2DP2​和DP3DP_3DP3​的模型M2M_2M2​和M3M_3M3​。在第一轮同步之后（r=1r=1r=1），DP1DP_1DP1​ 获得了M1M_1M1​和MnM_nMn​，DP4DP_4DP4​获得了M1,M2,M3和M4M_1,M_2,M_3和M_4M1​,M2​,M3​和M4​,DPnDP_nDPn​获得了Mn和Mn−1M_n和M_{n-1}Mn​和Mn−1​，经过m−1m-1m−1轮同步后（r=m−1r=m-1r=m−1），所有可信节点已经获得了其他所有可信节点的模型 （2）知识蒸馏 由于同步，每个可信节点从剩余的可信数据节点获得模型。然后，每个可信节点在本地进行知识蒸馏。通过知识蒸馏，强大的教师模型中的暗知识可以转移到知识很少的学生模型中。学生模型的损失函数如公式所示 LCEL_{CE}LCE​表示交叉熵，DKLD_{KL}DKL​表示KL散度，PPP表示softmax之后的模型输出，zzz表示模型logit层的输出，TTT表示蒸馏温度的超参 知识蒸馏的目的就是最小化LstudentL_{student}Lstudent​，使得学生模型更好的学习暗知识 RDFL利用KL散度来衡量模型之间的分布差异。 在RDFL算法的知识蒸馏步骤中，每个可信节点DPkDP_kDPk​将本地模型MkM_kMk​作为学生，而DPkDP_kDPk​拥有的其余模型将被用作教师来学习暗知识。 为了防止遭到不可信节点的数据中毒，RDFL只允许与模型MkM_kMk​KL差异最小的前30%的模型作为教师模型 随着FL轮数的增加，教师模型的数量会动态增加，以提高泛化能力，但不超过50%。每个可信节点只保留局部模型，知识蒸馏后丢弃剩余模型。在图3中，受信任的节点DP1DP_1DP1​在蒸馏后得到本地模型M1M_1M1​，DP4DP_4DP4​得到M4M_4M4​，DPnDP_nDPn​得到MnM_nMn​。然后，可信节点利用Ring-allreduce和顺时针原则来同步可信节点的本地模型。同步后，所有可信节点都有其他可信节点的本地模型。 （3）联邦平均 在这一步中，每个可信节点运行 FedAvg获得一个新的全局模型。然后，每个可信节点根据环形拓扑将新的全局模型逆时针发送给不可信节点，并开始下一次迭代。 3、IPFS和区块链 在传统的分散FL算法中[何等，2019]，数据节点间模型的传递占用大量通信开销，造成严重的通信压力。此外，这些通信正遭受篡改的安全风险，并且无法追踪模型的来源。 （1）通信压力 为了减轻沟通压力，GFL引入IPFS作为模型存储系统。IPFS由GFL的可信节点组成。IPFS的文件将被分成存储在不同节点上的多个部分，IPFS将生成对应于该文件的IPFS哈希。IPFS哈希是一个46字节的字符串，相应的文件可以通过IPFS哈希从IPFS获得。 （2）通信安全 为了提高分散的FL框架的安全性，GFL引入了区块链作为通信系统。 在GFL，数据节点发送的IPFS哈希以区块链事务的形式传输。每笔交易都通过一致算法进行验证，以降低篡改风险。此外，由于区块链记录了每个交易信息，GFL可以根据交易信息追溯到恶意节点。 值得注意的是，由于区块链的开放，区块链的任何节点都可以获得区块链的交易信息。为了避免IPFS散列的泄露，GFL对IPFS散列进行加密，以保护数据节点的隐私。 如何进行加密，密钥如何保存 框架设计 本节详细描述了GFL的体系结构和加密机制。 （1）架构 GFL由IPFS和区块链组成。就区块链而言，GFL利用以太网[伍德等人，2014年]作为区块链的实施。在GFL，区块链由所有数据节点组成，IPFS由可信节点组成。 智能合约是部署在区块链的协议。在GFL，数据节点通过调用智能合约的函数，将模型的IPFS哈希以事务的形式发送给区块链。区块链首先执行共识机制来验证事务是否被篡改，如果验证通过，事务将被打包成块。 如图4所示，GFL有两种类型的智能合同。控制合约负责控制所有FL任务的流程。存储合约负责存储模型的IPFS散列，每个FL任务都有一个独立的存储合约。 （2）加密机制 由于区块链的可见性，区块链的节点可以访问任何块中的交易信息，不可信数据节点中恶意节点的存在可能导致数据隐私泄露。为解决数据隐私泄露问题，GFL利用RSA非对称加密算法和AES对称加密算法对交易信息进行加密。 根据RDFL算法，数据节点DPh,h⊆[1,n]DP_h,h\\subseteq[1,n]DPh​,h⊆[1,n]将模型的IPFS哈希发送给它最近的可信节点DPk,k⊆(h,n]DP_k,k\\subseteq(h,n]DPk​,k⊆(h,n]，如果DPhDP_hDPh​和DPkDP_kDPk​是第一次通信，DPkDP_kDPk​生成一个AES密钥，并且使用DPhDP_hDPh​的公钥加密它，然后发送给DPhDP_hDPh​。DPhDP_hDPh​使用私钥解密得到这个AES密钥。然后IPFS哈希在DPhDP_hDPh​和DPkDP_kDPk​之间传输时就用AES密钥来进行加密。 这里不多此一举嘛？为什么不直接用非对称加密呢？DPhDP_hDPh​向DPkDP_kDPk​发送时就用DPkDP_kDPk​的公钥，反过来就用DPhDP_hDPh​的公钥加密，各自收到消息之后用自己的私钥解密就可以了啊。 实验和结果 在这一部分中，我们首先评估RDFL算法的分散FL性能，然后评估GFL的通信耗时和通信数据量。 1、RDFL 算法分析 我们通过仿真实验验证了RDFL算法的性能。模拟实验的设置如下: 数据集：CIFAR-10、CIFAR-100和MNIST 在这个实验中，我们模拟了5个(n = 5)数据节点。验证RDFL在恶意节点数据中毒下的FL性能。MNIST数据集被模拟为恶意数据集。我们将数据集划分为独立的同分布(IID)数据集，并将它们分配给数据节点。此外，为了验证算法在非数据集上的FL性能，我们利用潜在狄利克雷分配(LDA)[何等，2020]和标签划分方法将数据集划分为非数据集。当使用标签分区方法时，每个分区仅包括两类CIFAR-10或二十类CIFAR-100数据集。 模型设置：我们使用一个卷积神经网络(CNN)，它有三个3×3卷积层(第一个有32个通道，第二个有64个通道，第三个有64个通道，每个通道都有2×2最大池和ReLu激活)和两个FC层。 训练设置：在每个数据节点，我们使用SGD算法来训练上面提到的CNN模型。学习率和权重衰减都是0.001。批量为64。在每一轮FL中，数据节点执行5轮本地模型训练。 比较设置：我们假设所有不可信节点都是恶意节点，按照4种不同的比例在5个数据节点中设置恶意数据节点，比较RDFL算法和FedAvg的性能。此外，我们还比较了RDFL算法和FedAvg在无恶意节点的不同非IID数据集下的性能。 结果： 为了验证RDFL算法在恶意节点数据中毒情况下的分布式FL性能，我们进行了四种节点比率下的RDFL算法和FedAvg。图5显示了训练的过程，表1显示了在不同的节点比率下，RDFL算法比FedAvg具有更好的性能。 此外，为了验证RDFL算法在非IID数据集下的性能，我们使用潜在狄利克雷分配(LDA)和标签划分方法将数据集划分为5个分区，以比较RDFL算法和FedAvg的性能。图5显示了培训的过程。从表1可以看出，RDFL算法在非IID数据集上具有更好的性能。 2、通信分析 我们通过仿真实验验证了GFL的通信性能。模拟实验的设置如下: 实验设置：我们在IPFS和区块链建立了一个具有3个可信数据节点的网络(内存:16GBCPU:Intel Xeon Gold 5118 2.30GHz)，并利用Lenet-5型号和ResNet-50型号验证GFL的通信性能。 实验结果： 我们首先验证了传统分散FL框架的通信性能，然后验证了仅引入时的通信性能。最后验证了IPFS和区块链同时引入IPFS时GFL的通信性能。表2和表3显示，IPFS大大减少了通信时间和通信数据量。此外，由于区块链的共识算法，GFL引入区块链后，通信时间消耗略有增加。总之，GFL比传统的分布式FL框架有更好的通信性能。 结论 在本文中，我们提出了一个基于区块链的分布式FL框架，称为GFL，以解决现有的分布式FL框架的问题。GFL利用一致哈希算法和RDFL算法来提高通信性能、分布式的FL性能和稳定性。此外，GFL引入了IPFS和区块链，以进一步提高通信性能和FL安全性。","categories":[{"name":"区块链+联邦学习论文阅读笔记","slug":"区块链-联邦学习论文阅读笔记","permalink":"https://yao-chen-ecnu.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE-%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"区块链+联邦学习","slug":"区块链-联邦学习","permalink":"https://yao-chen-ecnu.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE-%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"}]},{"title":"A Blockchain-based Decentralized Federated Learning Framework with Committee Consensus","slug":"A Blockchain-based Decentralized Federated Learning Framework with Committee Consensus","date":"2021-04-19T06:57:34.057Z","updated":"2021-04-19T12:22:38.644Z","comments":true,"path":"2021/04/19/A Blockchain-based Decentralized Federated Learning Framework with Committee Consensus/","link":"","permalink":"https://yao-chen-ecnu.github.io/2021/04/19/A%20Blockchain-based%20Decentralized%20Federated%20Learning%20Framework%20with%20Committee%20Consensus/","excerpt":"","text":"摘要 联邦学习已经被广泛研究并应用于各种场景。在移动计算场景中，联合学习保护用户不暴露他们的私有数据，同时协作地为各种现实世界的应用程序训练全局模型。然而，由于恶意客户端或中央服务器不断攻击全局模型或用户隐私数据，联邦学习的安全性日益受到质疑。为了解决这些安全问题，我们提出了一个基于区块链的分布式联邦学习框架，即一个基于区块链的具有委员会共识的联邦学习框架。该框架将区块链用于全局模型存储和本地模型更新交换。为了实现提出的BFLC，我们还设计了一种创新的委员会共识机制，可以有效减少共识计算量，减少恶意攻击。然后我们讨论了BFLC的可扩展性，包括理论安全性、存储优化和激励。最后，我们使用真实数据集进行了实验，以验证BFLC框架的有效性。 引言 传统联邦学习的缺点： 在FL设置中，服务器执行更新聚合、客户端选择、全局模型维护等中心操作。服务器需要从众多客户端收集更新来完成聚合操作，还需要向这些客户端广播一个新的全局模型，这就对网络带宽提出了很高的要求。此外，基于云的服务器受到云服务提供商稳定性的影响。集中式服务器可以通过偏向某些客户端来扭曲全局模型。此外，一些恶意的中央服务器可以毒害模型，甚至从更新中收集客户端的隐私数据。因此，中央服务器的稳定性、公平性和安全性对FL至关重要。 本文的主要贡献： 提出了一个基于区块链的FL框架BFLC，它详细定义了模型存储模式、训练过程和新的委员会共识。 从技术上讨论了BFLC的可扩展性，包括社区中的节点管理、恶意节点攻击的分析和存储优化。 通过在真实的FL数据集上的实验证明了BFLC的有效性。我们还通过模拟恶意攻击验证了BFLC的安全性。 相关工作 目前区块链应用于联邦学习的三个挑战： 共识效率。对于基于区块链的方法来说，为每个块达成共识是一个不可避免的过程。考虑到FL设置中的大量学习节点，广播共识非常耗时。因此，降低共识成本不是小事。相关作品中有一篇[10]选择了一位领导者来执行共识。然而，该标准依赖于许多外部数据。 模型安全性。该框架应防止全球模型暴露于未经授权的设备和中毒。系统的安全性很少在基于区块链的FL环境下进行研究。 框架可扩展性。当将这些训练框架应用到现实世界的应用中时，我们总是需要添加细节规则来适应不同的场景。因此，框架的可扩展性决定了它们的应用范围。 本文提出的框架 A. 区块链存储 为了实现权限控制，BFLC的存储是一个联盟区块链系统，只有授权的设备才能访问FL训练内容。在区块链，我们设计了两个不同的块来存储全局模型和局部更新(如图2所示)，它们统称为学习信息。为了简单起见，我们假设一个块中只放置一个学习信息。 一开始，一个随机初始化的模型被放入#0块，然后第0轮训练开始。节点访问当前模型并执行局部训练，并将验证后的局部梯度放入新的更新块。当连续有足够的更新块时，智能契约触发聚合，下一轮的新模型被生成并放置在链上。我们要注意的是，FL训练只依赖最新的模型块，存储历史块是为了故障回退和块验证。 假设每轮需要kkk个更新，共进行ttt轮迭代，那么#t∗（k+1）t*（k+1）t∗（k+1）块代表第t轮的模型块，#[t∗(k+1)+1,(t+1)∗(k+1)−1][t*(k+1)+1,(t+1)*(k+1)-1][t∗(k+1)+1,(t+1)∗(k+1)−1]为第ttt轮迭代的更新块 模型块：块头，迭代轮数ttt，和全局模型 更新块：块头，迭代轮数ttt，本地更新模型，上传地址和更新分数 B. 委员会共识机制 选举出几个诚实的节点组成一个验证委员会负责模型验证和共识出块，其他节点进行本地训练并将模型上传给共识委员会。然后，委员会验证更新，并给它们打分。只有合格的更新将被打包到区块链。在下一轮开始时，根据上一轮的节点分数选举一个新的委员会。 委员会如何进行验证： 委员会成员通过将他们的数据视为一个验证集来验证本地更新，验证的准确性成为分数。这是最小化的方法，不需要委员会的进一步操作，只需要运行学习模型的基本能力。综合各委员会成员的得分后，中位数将成为本次更新的得分。 BFLC可以实现这些优点: 高效率:只有几个节点会验证更新，而不是广播到每个节点并达成协议。 K倍交叉验证:委员不会全面参加当地培训。因此，委员会的本地数据被视为验证集。随着每轮委员会成员的交替，验证集也随之改变。在这种情况下，在FL上实现了k倍交叉验证。 反恶意:基于验证分数，智能合约将选出相应的表现较好的节点，组成下一轮培训的新委员会。这意味着所选择的本地数据分布是群居的，并且该节点不是恶意的。 委员会共识机制描述不够具体。最初的委员会怎么选举，如何判断委员会成员是诚实的，万一委员会节点中混入恶意节点，委员会节点本地运行模型会不会造成节点的模型泄露，根据怎样的具体标准进行打分，如何保证委员会的打分是可信的？ C. 模型训练 在FL中，为了安全和隐私，原始数据将保存在本地的节点中，这些节点只将梯度上传到区块链。 存在两点挑战： 本地数据分布可能不是独立且同分布的(非IID)—&gt;每轮只需要一定数量的局部更新 设备不总是可用的（可能存在掉线的情况）-----&gt;节点随时主动获取当前最新的全局模型进行训练，当节点贡献局部梯度更新时，由委员会验证，验证通过则为其发放奖励 每一轮，当委员会验证足够的本地更新时，聚合过程被激活。委员会将这些经过验证的更新汇总成一个新的全局模型。新的全局模型写入区块链后，委员会将再次选举，下一轮训练开始。 讨论 A. 节点管理和奖励机制 节点管理 为了控制权限，指定组成训练社区的初始节点负责节点管理，即作为管理者。在加入训练社区之前，每个设备都必须经过经理的验证。此验证处于黑名单模式:如果设备因不当行为(如提交误导性更新、传播私人模型)被踢出社区，设备将被拒绝。 根据建议的区块链存储结构，在新节点加入后，可以在链上快速找到最新的全局模型。节点可以立即使用模型完成本地任务，也可以用本地数据更新模型，经共识委员会验证后在链上获得分数。 奖励机制 社区中的节点总是可以在不提交更新的情况下使用该模型，因此需要有效的激励来鼓励节点向全局模型提供更新。为了解决这个问题，我们提出了一种叫做按贡献分享利润的激励机制。 许可费:每台设备都要为全局模型的访问许可付费，这些费用由管理者保管。然后，节点可以无限制地访问社区中的最新模型。 利润分享:每轮汇总后，经理根据提交更新的分数将奖励分配给相应的节点。 因此，频繁提供更新可以获得更多的回报，不断更新的全局模型将吸引更多的节点参与。这种激励机制具有很高的可扩展性，以适应不同的现实世界应用。 B. 委员会选举 在每一轮结束时，从经验证的更新提供者中选出一个新的委员会。 随机选举:从经过验证的节点中随机选择新的委员会成员。从机器学习的角度来看，这种方法提高了模型的泛化能力，减少了过拟合。然而，当恶意节点伪装成正常节点时，对恶意攻击的抵抗力较弱。 分数选举:认证分数最高的供应商组成新的委员会。由于委员会中缺少部分节点，这可能会加剧样本的不均匀分布。然而，对于恶意节点攻击，这种方法显著增加了攻击成本，并带来了更多的安全性和稳定性。 多因素优化:这种方法考虑了设备的多种因素(即网络传输速率)和最佳选择的验证分数。但是，这种优化会带来额外的计算开销。因此，应该根据实际情况和相关要求来应用这种方法。 C. 恶意节点 恶意节点被定义为提交不正确的恶意模型更新的节点。 我们将所有节点的数量表示为NNN，其中委员会成员的数量为MMM，其余的N−MN-MN−M个节点为训练节点。当且仅当超过m/2m/2m/2个委员会成员合谋时，而已更新才会被聚合。然而在上一轮中，委员会成员时表现最好的M个成员，这就意味着这些恶意委员会成员的更新倍上一轮委员会中超过m/2m/2m/2个节点接受，这是一个无线循环过程，因此只要第一轮的委员会中有超过m/2m/2m/2诚实节点，就没有恶意节点可以进入委员会并且损害全局模型。 考虑另外一个极端情况：恶意节点通过伪装成正常节点合谋赢得委员会席位。当恶意节点占据一半席位时，攻击开始。 分析:参与节点数量为AAA，AAA中恶意节点占的百分比为q,q∈(0,1)q,q\\in(0,1)q,q∈(0,1),委员会成员占的百分比为p∈(0,1)p\\in(0,1)p∈(0,1)，攻击目标是抢占委员会中超过A∗P/2A*P/2A∗P/2的席位。假设每个节点的性能都是相似的，攻击成功事件就可以描述为：委员会节点A∗pA*pA∗p个中，有超过半数来自A∗pA*pA∗p，设定A为1000 我们应该注意到，只有当恶意百分比大于50%时，攻击成功的概率才能明显大于0。这个结论类似于区块链电力系统51%的攻击。换句话说，在一个分布式社区中，恶意节点应该拥有51%的计算资源来攻击系统，而代价远远超过好处。此外，历史模型和更新存储在区块链上，因此，在攻击发生后，可以选择回撤。 D. 存储优化 在实际应用中，存储开销是决定训练设备硬件要求的一个重要因素。基于上述区块链存储方案(如图2所示)，可以快速找到最新的全局模型。虽然历史模型和更新可以提供恢复功能，但也占用了巨大的存储空间。 这里我们给出一个简单可行的存储开销降低方案:容量不足的节点可以在本地删除历史块，只保留最新的模型和本轮的更新。这样可以解决一些节点存储空间不足的问题，同时在核心节点上保留了灾难恢复和块验证的能力。但是这种方法的缺点也很明显。区块链的可信度随着节点的删除而降低。在相互不信任的培训社区中，出于安全考虑，每个节点都不能使用该方案。 因此，可信可靠的第三方存储可能是更好的解决方案。区块链仅维护每个模型或更新文件所在的网络地址和修改操作记录。其他节点与集中式存储交互，以获取最新型号或上传更新。该集中式存储将负责灾难恢复备份和分布式文件存储服务。 实验 数据集：FEMNIST 该数据集包含用于手写字符图像分类任务的80，5263个样本和3550个用户，并且包含62个不同的类别(10个数字，26个小写，26个大写)。 模拟了900个设备，其中本地数据集在数量上是不平衡的，并且在分布上不是独立的 区块链系统选用FISCO，是一个基于PBFT共识的一个去跨链平台 智能合约使用solidity语言进行开发 学习模型用Python 3.7.6和Tensorflow 1.14.0编写，在Geforce RTX 2080 ti GPU上执行 我们将BFLC与基础FL [12]框架和独立培训框架作为基线进行比较。每个框架执行经典的图像分类模型AlexNet [14]作为全局模型，并固定一组模型超参数以确保公平性。在实验设置方面，我们将每轮活动节点的比例定义为k%，其中40%将在下一轮BFLC中当选为委员会成员。基础FL的训练节点比例也是k%。同时，独立训练将利用整个数据集。在不同k值的条件下，我们将他们的表现记录在表一中。 从表一可以看出，随着活动节点比例的增加，BFLC的性能不断接近基本FL框架的效果，与数据集完整的独立训练相比，只有轻微的损失。值得一提的是，BFLC可以通过委员会共识机制显著降低共识的消耗。 恶意攻击下的实验 我们假设恶意节点的攻击模式是带有点态高斯随机噪声的随机扰动。 基本FL不会执行任何防御措施，随机选择的主动节点生成的模型更新会被聚合。CwMed构建一个全局梯度，其中每个条目是具有相同坐标的局部梯度中条目的中间值。BFLC依靠上面提到的委员会共识来抵抗攻击。每次更新都会从委员会获得一个分数(即局部预测精度的中位数)。 为了增强攻击的有效性，我们假设恶意节点是共谋的，即恶意委员会的成员会对恶意更新给予随机的高分(例如90%̘100%)。活跃节点比例定为10%，下一轮选举20%为委员会。如图4所示，BFLC可以抵抗比比较方法高得多的恶意节点比例。这表明，在委员会机制的帮助下，边境事务局的工作卓有成效。 结论 基于一个可信的区块链系统，我们提出了BFLC，这是一个利用委员会共识的分散的、联合的学习框架。这样的委员会共识可以有效避免恶意中心服务器或恶意节点的影响。在实验部分，我们采用真实数据集验证了BFLC框架的有效性，该数据集可以获得类似于联邦学习中集中训练的全局模型。我们还讨论了BFLC的可扩展性，它在安全性、数据存储和激励机制方面具有广阔的研究前景。","categories":[{"name":"区块链+联邦学习论文阅读笔记","slug":"区块链-联邦学习论文阅读笔记","permalink":"https://yao-chen-ecnu.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE-%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"区块链+联邦学习","slug":"区块链-联邦学习","permalink":"https://yao-chen-ecnu.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE-%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"}]},{"title":"Biscotti A Blockchain System for Private and Secure Federated Learning","slug":"Biscotti A Blockchain System for Private and Secure Federated Learning","date":"2021-04-15T04:35:08.489Z","updated":"2021-04-19T08:35:05.973Z","comments":true,"path":"2021/04/15/Biscotti A Blockchain System for Private and Secure Federated Learning/","link":"","permalink":"https://yao-chen-ecnu.github.io/2021/04/15/Biscotti%20A%20Blockchain%20System%20for%20Private%20and%20Secure%20Federated%20Learning/","excerpt":"","text":"摘要 联合学习是支持安全多方机器学习(ML)的最新技术:数据保存在所有者的设备上，模型的更新通过安全协议进行聚合。然而，这个过程假设一个可信的集中式基础设施来进行协调，并且客户端必须相信中央服务不使用客户端数据的副产品。除此之外，一组恶意客户端还可能通过执行中毒攻击来损害模型的性能。作为回应，我们提出了Biscotti:一种完全分散的对等(P2P)多方消息传递方法，它使用区块链和加密原语来协调对等客户端之间的隐私保护消息传递过程。我们的评估表明，Biscotti是可扩展的、容错的，并且能够抵御已知的攻击。例如，当系统中存在30%的对手时，Biscotti能够保护单个客户端更新的隐私，并保持全局模型的大规模性能。 背景 机器学习应用中的一个常见需求是收集大量的训练数据。这些数据经常是分布式的，例如在医院或物联网部署中的设备之间。然而，当在多方环境中训练ML模型时，用户必须与集中式服务共享他们潜在的敏感信息。这种共享对于不愿意信任第三方的用户或公司来说是有问题的。例如，制药公司在药物发现方面相互竞争，很少共享数据。此外，互联网用户越来越意识到他们的数据的价值，并希望保持对其数据的控制。为了避免直接共享敏感数据，联合学习是大规模安全多方ML的一个突出解决方案:客户端通过可信的聚合器来训练共享模型，而不会暴露其底层数据或计算。 攻击： 毒化攻击 窃取隐私：对手也可以在联合学习中攻击其他客户端的隐私:在信息泄漏攻击中，对手伪装成诚实的数据提供者，并试图通过观察目标的共享模型更新来推断目标客户端的敏感训练数据的属性 先前的解决办法：集中式的异常检测、差分隐私、安全聚合 但据我们所知，同时解决这两种威胁的私有分散解决方案尚不存在。 此外，这些方法不适用于缺乏可信的中央权威的分散环境。因为ML不需要强一致或一致性来收敛，所以传统的强一致协议，如拜占庭容错(BFT)协议对机器学习工作负载的限制过于严格。 主要的贡献： 我们的主要贡献是将几种现有技术整合到一个连贯的系统中，在高度分布式P2P环境中提供安全和私有的多方机器学习。特别是，比肖蒂通过多克鲁姆防御防止对等体毒害模型[42]，通过不同的私人噪音提供隐私[22]，[23]，并使用沙米尔秘密进行安全聚合[43]。 我们发现Biscotti可以在266.7分钟内在60000个图像数据集上训练一个有200个同伴的MNIST softmax模型，同时可以抵抗高达30%的敌对同伴。此外，我们还证明了Biscotti的设计对于需要了解客户端SGD更新的信息泄漏攻击[13]是有弹性的，而且Biscotti对于之前工作中的中毒攻击[44]也是有弹性的。Biscotti还具有容错能力，可以应对每1.875秒就会发生故障的节点，并提供模型训练，即使节点发生故障也可以收敛。 挑战与关键技术 女巫攻击：基于VRF和POF的一致性哈希 毒化攻击：使用Multi-Krum进行验证更新 信息窃取：差分隐私 隐私性：安全聚合和密钥共享 一些假设 设计假设 POF是基于POS的 区块链拓扑 机器学习：使用SGD 攻击假设 在女巫攻击中，我们假设对手控制多个参与方，但不超过总体的30% 将中毒攻击限制为错误标记数据，导致训练过的模型对其进行错误分类，不包括后门攻击和基于梯度上升的攻击 当对手进行信息泄漏攻击时，我们假设他们的目标是学习受害者的本地数据集的属性。具体地说，我们提供了记录级别的隐私，这可以防止从用户数据集中对单个示例进行反匿名化。由于安全聚合的漏洞，我们不考虑带有边信息的信息泄漏攻击，也不考虑试图学习整个目标类属性的类级隐私攻击。 BISCOTTI设计 设计目标： 收敛到最优全局模型(在联邦学习设置中没有对手的情况下训练的同一模型); 通过验证对等体模型更新来防止中毒; 通过防止信息泄露攻击来保持对等体训练数据的私密性 总体设计： 每出一个块代表完成一次SGD迭代 1：每个peer在本地计算SGD更新值，即梯度 2：每个peer从一个noising peers中获取噪声，这个noising peers是由VRF算法挑选出来的 3：每个peer为自己的梯度添加上噪声，那么现在得到了masked update 4：然后这个masked update会被验证委员会(verification committee)进行验证，该验证委员会也是由VRF算法选举出来的，如果peer的masked update可以通过Multi-KRUM算法的验证，那么验证委员会的每一个成员会为该peer的unmasked update签署一个承诺 5：如果大多数委员会的成员都签署了一个更新 6：那么这个更新就会通过Shamir secret shares协议分成多份 7：然后多份更新就会被发送到一个聚合委员会(aggregation committee)中进行聚合，聚会委员会会执行一个安全的协议去聚合unmaked update。 完成聚合后所有对梯度有贡献的peers以及担任了验证和聚合委员会的都会受到额外的奖励。 8：聚合后的updates添加到全局的模型中，并存储在一个新的区块中，同时将更新后的模型会广播给所有的peers，并且新产生的区块会被添加到账本上 训练初始化 创世块由可信任的第三方创立 包含以下信息，所有peers都可以获取到创世块中的信息： 初始模型状态w0和预计T的迭代次数 用于创建SGD更新承诺的公钥PK(见附录C) 系统中所有其他对等体的公钥,用于提交和验证签名验证期间 每个peer的噪声(见图3和附录B) 初始的权益分配 当有新的区块被追加时执行的权益更新功能。 区块链设计 为了验证聚合是真实计算的，需要在块中包含单个更新。然而，单独存储它们会泄露个人私人训练数据[13]、[20]的信息。使用polynomial commitments 多项式承诺进行SGD更新，并将其映射到椭圆曲线上的一个点(详见附录C)。承诺通过隐藏个体更新来提供隐私，但是可以同态组合以验证aggregatorP㼿wiwas对全局模型的更新是诚实计算的。如果提交的更新列表等于总和，则以下等式成立: 根据权益进行角色选举","categories":[{"name":"区块链+联邦学习论文阅读笔记","slug":"区块链-联邦学习论文阅读笔记","permalink":"https://yao-chen-ecnu.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE-%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"区块链+联邦学习","slug":"区块链-联邦学习","permalink":"https://yao-chen-ecnu.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE-%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"}]},{"title":"共识算法","slug":"共识算法","date":"2021-03-24T08:40:28.069Z","updated":"2021-03-24T08:40:28.070Z","comments":true,"path":"2021/03/24/共识算法/","link":"","permalink":"https://yao-chen-ecnu.github.io/2021/03/24/%E5%85%B1%E8%AF%86%E7%AE%97%E6%B3%95/","excerpt":"","text":"区块链共识算法之Raft&amp;Pbft&amp;Rbft 什么是共识算法 区块链技术中，共识算法是其中核心的一个组成部分。 **什么是共识？**从两个层面理解共识：第一个层面是点，即多个节点对某个数据达成一致共识。第二个层面是线，即多个节点对多个数据的顺序达成共识。其中对数据顺序达成一致共识是很多共识算法要解决的根本问题。 共识算法根据区块链的分类同样可以分成三大类：公链，联盟链和私链。 私链：私链的适用环境一般是不考虑集群中存在作恶节点，只考虑因为系统或者网络原因导致的故障节点。如paxo，raft。 联盟链：联盟链的适用环境除了需要考虑集群中存在故障节点，还需要考虑集群中存在作恶节点。对于联盟链，每个新加入的节点都是需要验证和审核的。如pbft。 公链：公链不断需要考虑网络中存在故障节点，还需要考虑作恶节点。公链中的节点可以很自由的加入或者退出，不需要严格的验证和审核。 一、raft和pbft的最大容错节点数 故障节点：节点因为系统繁忙、宕机或者网络问题等其他异常情况导致的无响应。 作恶节点：除了可以对集群的其他节点的请求无响应之外，还可以故意的发送错误的数据，或者给不同的其他节点发送不同的数据，使整个集群的节点最终无法达成共识。 raft是针对私链的共识算法，所以raft的容错只支持容错故障节点，不支持容错作恶节点。假设集群总节点数为nnn，故障节点为 fff ，根据小数服从多数的原则，集群里正常节点只需要比 fff 个节点再多一个节点，即 f+1f+1f+1个节点，正确节点的数量就会比故障节点数量多，那么集群就能达成共识。因此 raft 算法支持的最大容错节点数量是(n−1)/2(n-1)/2(n−1)/2。 对于 pbft 算法，因为 pbft 算法的除了需要支持容错故障节点之外，还需要支持容错作恶节点。假设集群节点数为 NNN，有问题的节点为 fff。有问题的节点中，可以既是故障节点，也可以是作恶节点，或者只是故障节点或者只是作恶节点。那么会产生以下两种极端情况： 第一种情况，fff 个有问题节点既是故障节点，又是作恶节点，那么根据小数服从多数的原则，集群里正常节点只需要比fff个节点再多一个节点，即 f+1f+1f+1个节点，确节点的数量就会比故障节点数量多，那么集群就能达成共识。也就是说这种情况支持的最大容错节点数量是 (n−1)/2(n-1)/2(n−1)/2。 第二种情况，故障节点和作恶节点都是不同的节点。那么就会有 fff个故障节点和fff个作恶节点，当发现节点是故障节点后，会被集群排除在外，剩下fff个作恶节点，那么根据小数服从多数的原则，集群里正常节点只需要比fff个节点再多一个节点，即 f+1f+1f+1个节点，正确节点的数量就会比作恶节点数量多，那么集群就能达成共识。所以，所有类型的节点数量加起来就是f+1f+1f+1 个正确节点，fff个故障节点和fff个问题节点，即 3f+1=n3f+1=n3f+1=n。 结合上述两种情况，因此 pbft 算法支持的最大容错节点数量是(n−1)/3(n-1)/3(n−1)/3。 二、raft算法 raft算法包含三种角色，分别是：跟随者（follower）、候选人（candidate）和领导者（leader）。 leader: 处理所有客户端交互，日志复制等，一般一次只有一个Leader. follower: 类似选民，完全被动 candidate候选人: 类似Proposer律师，可以被选为一个新的领导者。 集群中的任意节点在某一时刻只能是这三种状态的其中一种，这三种角色是可以随着时间和条件的变化而相互转换的。 每个节点上都有一个倒计时器 (Election Timeout)，时间随机在 150ms 到 300ms 之间。有几种情况会重设 Timeout： 收到选举的请求 收到 Leader 的 Heartbeat raft算法主要又两个过程：第一个是领导者选举，第二个是日志复制，其中日志复制过程分为记录日志和提交数据两个阶段。 算法流程参考：https://www.jianshu.com/p/8e4bbe7e276c Raft 官网：https://raft.github.io/ Raft 原理动画 (推荐看看)：http://thesecretlivesofdata.com/raft/ Raft 算法解析图片来源：http://www.infoq.com/cn/articles/coreos-analyse-etcd 三、pbft 算法 的提出主要是为了解决拜占庭将军问题。 四、rbft算法","categories":[{"name":"区块链","slug":"区块链","permalink":"https://yao-chen-ecnu.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://yao-chen-ecnu.github.io/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"分类算法总结","slug":"分类算法总结","date":"2021-03-16T02:06:42.714Z","updated":"2021-03-22T05:35:38.642Z","comments":true,"path":"2021/03/16/分类算法总结/","link":"","permalink":"https://yao-chen-ecnu.github.io/2021/03/16/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/","excerpt":"","text":"分类算法总结 K-近邻 k-近邻算法采用测量不同特征值之间的距离方法进行分类。 工作原理 存在一个样本数据集合，也称作训练样本集，并且样本集中每个数据都存在标签，即我们知道样本集中每一数据与所属分类的对应关系。输入没有标签的新数据后，将新数据的每个特征与样本集中数据对应的特征进行比较，然后算法提取样本集中特征最相似数据（最近邻）的分类标签。最后，选择k个最相似数据中出现次数最多的分类，作为新数据的分类。 优点：精度高、对异常值不敏感、无数据输入假定。 缺点：计算复杂度高、空间复杂度高。 适用数据范围：数值型和标称型。 k-近邻算法的一般流程 (1) 收集数据：可以使用任何方法。 (2) 准备数据：距离计算所需要的数值，最好是结构化的数据格式。 (3) 分析数据：可以使用任何方法。 (4) 训练算法：此步骤不适用于k-近邻算法。 (5) 测试算法：计算错误率。 (6) 使用算法：首先需要输入样本数据和结构化的输出结果，然后运行k-近邻算法判定输入数据分别属于哪个分类，最后应用对计算出的分类执行后续的处理。 实施kNN 算法 对未知类别属性的数据集中的每个点依次执行以下操作： (1) 计算已知类别数据集中的点与当前点之间的距离（通常需要归一化处理）； (2) 按照距离递增次序排序； (3) 选取与当前点距离最小的k个点； (4) 确定前k个点所在类别的出现频率； (5) 返回前k个点出现频率最高的类别作为当前点的预测分类。 总结 k-近邻算法是基于实例的学习，使用算法时我们必须有接近实际数据的训练样本数据。k-近邻算法必须保存全部数据集，如果训练数据集的很大，必须使用大量的存储空间。此外，由于必须对数据集中的每个数据计算距离值，实际使用时可能非常耗时。k-近邻算法的另一个缺陷是它无法给出任何数据的基础结构信息，因此也无法知晓平均实例样本和典型实例样本具有什么特征。 决策树 优点：计算复杂度不高，输出结果易于理解，对中间值的缺失不敏感，可以处理不相关特征数据。 缺点：可能会产生过度匹配问题。 适用数据类型：数值型和标称型。 决策树的一般流程 (1) 收集数据：可以使用任何方法。 (2) 准备数据：树构造算法只适用于标称型数据，因此数值型数据必须离散化。 (3) 分析数据：可以使用任何方法，构造树完成之后，我们应该检查图形是否符合预期。 (4) 训练算法：构造树的数据结构。 (5) 测试算法：使用经验树计算错误率。 (6) 使用算法：此步骤可以适用于任何监督学习算法，而使用决策树可以更好地理解数据的内在含义。 概念 熵 信息：如果待分类的事务可能划分在多个分类之中，则符号xix_ixi​的信息定义为 l(xi)=−log2p(xi)l(x_i)=-log_2p(x_i) l(xi​)=−log2​p(xi​) 其中p(xi)p(x_i)p(xi​)是选择该分类的概率。 熵，是信息的期望。我们需要计算所有类别，所有可能值包含的信息期望值，通过下面的公式得到： H=−∑n=1np(xi)log2p(xi)H=-\\sum_{n=1}^{n}{p(x_i)log_2p(x_i)} H=−n=1∑n​p(xi​)log2​p(xi​) 其中nnn是分类的数目。 当熵中的概率由数据估计(特别是最大似然估计)得到时，所对应的熵称为 经验熵(empirical entropy)。 假定定义贷款申请样本数据表中的数据为训练数据集DDD，则训练数据集D的经验熵为H(D)H(D)H(D)，∣D∣|D|∣D∣表示其样本容量，及样本个数。设有KKK个类$ C_k，k = 1,2,3,···,K,,,|C_k|为属于类的为属于类的为属于类的C_k$样本个数，这经验熵公式可以写为： H(D)=∑k=1K∣Ck∣∣D∣log2∣Ck∣∣D∣H(D)=\\sum_{k=1}^{K}{\\frac{|C_k|}{|D|}log_2\\frac{|C_k|}{|D|}} H(D)=k=1∑K​∣D∣∣Ck​∣​log2​∣D∣∣Ck​∣​ 信息增益 在划分数据集之前之后信息发生的变化称为 信息增益，知道如何计算信息增益，就可以计算每个特征值划分数据集获得的 信息增益，获得 信息增益 最高的特征就是最好的选择。 条件熵 H(Y|X) 表示在已知随机变量X的条件下随机变量Y的不确定性，随机变量X给定的条件下随机变量Y的 条件熵(conditional entropy) H(Y|X)，定义X在给定Y条件下的条件概率分布的熵对X的数学期望： H(Y∣X)=∑i=1npiH(Y∣X=xi)H(Y|X)=\\sum_{i=1}^{n}{p_iH(Y|X=x_i)} H(Y∣X)=i=1∑n​pi​H(Y∣X=xi​) 这里，pi=P(X=xi),i=1,2,...,np_i=P(X=x_i),i=1,2,...,npi​=P(X=xi​),i=1,2,...,n。同理，当 条件熵 中的概率由数据估计(特别是极大似然估计)得到时，所对应的 条件熵 成为 条件经验熵(empirical conditional entropy)。 信息增益 是相对于特征而言的。所以，特征A对训练数据集D的信息增益g(D,A)g(D,A)g(D,A)，定义为集合D的D的D的经验熵H(D)H(D)H(D)与特征AAA给定条件下DDD的经验条件熵H(D∣A)H(D|A)H(D∣A)之差，即 g(D,A)=H(D)−H(D∣A)g(D,A)= H(D)-H(D|A) g(D,A)=H(D)−H(D∣A) 一般地，熵H(D)H(D)H(D)与条件熵H(D∣A)H(D|A)H(D∣A)之差称为 互信息(mutual information)。决策树学习中的 信息增益 等价于训练数据集中类与特征的 互信息。 设特征AAA有nnn个不同的取值a1,a2,...,ana_1,a_2,...,a_na1​,a2​,...,an​，根据特征AAA的取值将DDD划分为nnn个子集D1,D2,...,DnD_1,D_2,...,D_nD1​,D2​,...,Dn​,∣Di∣|D_i|∣Di​∣为DiD_iDi​的样本个数。记子集 DiD_iDi​中属于CkC_kCk​的样本的集合为DikD_ikDi​k,即Dik=DiD_ik=D_iDi​k=Di​的样本个数。于是经验条件熵的公式可以写为： H(D∣A)=∑i=1n∣Di∣∣D∣H(Di)=−∑i=1n∣Di∣∣Di∣∑k=1K∣Dik∣∣Di∣log2∣Dik∣∣Di∣H(D|A)=\\sum_{i=1}^{n}{\\frac{|D_i|}{|D|}H(D_i)}=-\\sum_{i=1}^{n}{\\frac{|D_{i}|}{|D_i|}\\sum_{k=1}^K{\\frac{|D_{ik}|}{|D_i|}log_2\\frac{|D_{ik}|}{|D_i|}}} H(D∣A)=i=1∑n​∣D∣∣Di​∣​H(Di​)=−i=1∑n​∣Di​∣∣Di​∣​k=1∑K​∣Di​∣∣Dik​∣​log2​∣Di​∣∣Dik​∣​ 决策树的生成与修剪 ID3算法的核心是在决策树各个结点上对应 信息增益 准则选择特征，递归地构建决策树，ID3相当于用极大似然法进行概率模型的选择。 具体方法是： 从根结点(root node)开始，对结点计算所有可能的特征的信息增益，选择信息增益最大的特征作为结点的特征，由该特征的不同取值建立子节点； 再对子结点递归地调用以上方法，构建决策树； 直到所有特征的信息增益均很小或没有特征可以选择为止，最后得到一个决策树。 使用决策树进行分类： 依靠训练数据构造了决策树之后，可以将它用于实际数据的分类。在执行数据分类时，需要决策树以及用于构造树的标签向量；然后，程序比较测试数据与决策树上的数值，递归执行该过程直到进入叶子结点；最后将测试数据定义为叶子结点所属的类型。 总结 决策树分类器就像带有终止块的流程图，终止块表示分类结果。开始处理数据集时，首先需要测量集合中数据的不一致性，也就是熵，然后寻找最优方案划分数据集，直到数据集中的所有数据属于同一分类。ID3算法可以用于划分标称型数据集。构建决策树时，通常采用递归的方法将数据集转化为决策树。一般并不构造新的数据结构，而是使用Python语言内嵌的数据结构字典存储树节点信息。 使用Matplotlib的注解功能，可以将存储的树结构转化为容易理解的图形。Python语言的pickle模块可用于存储决策树的结构。隐形眼镜的例子表明决策树可能会产生过多的数据集划分，从而产生过度匹配数据集的问题。我们可以通过裁剪决策树，合并相邻的无法产生大量信息增益的叶节点，消除过度匹配问题。还有其他的决策树的构造算法，最流行的是C4.5和CART 朴素贝叶斯方法 朴素贝叶斯法是基于贝叶斯定理与特征条件独立假设的分类方法，是有监督的学习算法。现实生活中朴素贝叶斯算法应用非常广泛，如文本分类，垃圾邮件的分类，信用评估，钓鱼网站检测等等。 优点：在数据较少的情况下仍然有效，可以处理多类别问题。 缺点：对于输入数据的准备方式较为敏感。 适用数据类型：标称型数据。 概念 朴素：整个形式化过程只做最原始、最简单的假设。 贝叶斯概率 引入先验知识和逻辑推理 来处理不确定命题。（另一种概率解释称为频数概率（frequency probability），它只从数据本身获得结论，并不考虑逻辑推理及先验知识。） 贝叶斯准则：即如果已知P(x∣c)P(x|c)P(x∣c)，要求P(c∣x)P(c|x)P(c∣x)，那么可以使用下面的计算方法： p(c∣x)=p(x∣c)p(c)p(x)p(c|x)=\\frac{p(x|c)p(c)}{p(x)} p(c∣x)=p(x)p(x∣c)p(c)​ 全概率公式：表示达到某个目的的多种方式各自概率的和 P(B)=P(B∣A)P(A)+P(B∣A′)P(A′)P(B)=P(B|A)P(A)+P(B|A&#x27;)P(A&#x27;) P(B)=P(B∣A)P(A)+P(B∣A′)P(A′) 对条件概率公式进行变形，可以得到如下形式： P(A∣B)=P(A)P(B∣A)P(B)P(A|B)=P(A)\\frac{P(B|A)}{P(B)} P(A∣B)=P(A)P(B)P(B∣A)​ P(A)称为&quot;先验概率&quot;（Prior probability），即在B事件发生之前，对A事件概率的一个判断。 P(A|B)称为&quot;后验概率&quot;（Posterior probability），即在B事件发生之后，对A事件概率的重新评估。 P(B|A)/P(B)称为&quot;可能性函数&quot;（Likelyhood），这是一个调整因子，使得预估概率更接近真实概率。 条件概率可以理解成下面的式子：后验概率 ＝ 先验概率 ｘ 调整因子 朴素贝叶斯对条件概率分布做了条件独立性的假设 假设有n个特征： P(a∣X)=p(X∣a)p(a)=p(x1,x2,...,xn∣a)p(a)P(a|X)=p(X|a)p(a)=p(x_1,x_2,...,x_n|a)p(a) P(a∣X)=p(X∣a)p(a)=p(x1​,x2​,...,xn​∣a)p(a) 由于每个特征都是独立的，我们可以进一步拆分公式： p(a∣X)={p(x1∣a)∗p(x2∣a)∗p(x3∣a)∗...∗p(xn∣a)}p(a)p(a|X)=\\left \\{p(x_1|a)*p(x_2|a)*p(x_3|a)*...*p(x_n|a)\\right \\}p(a) p(a∣X)={p(x1​∣a)∗p(x2​∣a)∗p(x3​∣a)∗...∗p(xn​∣a)}p(a) 这就是贝叶斯分类器的基本方法：在统计资料的基础上，依据某些特征，计算各个类别的概率，从而实现分类。 朴素贝叶斯实现过程中的问题 零概率 拉普拉斯平滑(Laplace Smoothing) 又被称为 加1平滑，是比较常用的平滑方法，它就是为了解决0概率问题。可以将所有词的出现数初始化为1，并将分母初始化为2 下溢出 下溢出是由于太多很小的数相乘造成的。当计算乘积：p(w0∣ci)p(w1∣ci)p(w2∣ci)...p(wN∣ci)p(w_0|c_i)p(w_1|c_i)p(w_2|c_i)...p(w_N|c_i)p(w0​∣ci​)p(w1​∣ci​)p(w2​∣ci​)...p(wN​∣ci​) 由于大部分因子都非常小，所以程序会下溢出或者得到不正确的答案。一种解决办法是对乘积取 自然对数。在代数中有ln(a∗b)=lna+lnbln(a*b)=lna+lnbln(a∗b)=lna+lnb，于是通过求对数可以避免下溢出或者浮点数舍入导致的错误。同时，采用 自然对数 进行处理不会有任何损失。 总结 对于分类而言，使用 概率 有时要比使用 硬规则 更为有效。贝叶斯概率及贝叶斯准则提供了一种利用已知值来估计未知概率的有效方法。可以通过 特征之间的条件独立性假设，降低对数据量的需求。独立性假设是指一个词的出现概率并不依赖于文档中的其他词。当然我们也知道这个假设过于简单。这就是之所以称为 朴素贝叶斯 的原因。尽管条件独立性假设并不正确，但是朴素贝叶斯仍然是一种有效的分类器。 利用现代编程语言来实现朴素贝叶斯时需要考虑很多实际因素。下溢出 就是其中一个问题，它可以通过对概率取对数来解决。还有其他一些方面的改进，比如说移除停用词，当然也可以花大量时间对切分器进行优化。 Logistic 回归 假设现在有一些数据点，用一条直线对这些点进行拟合（该线称为 最佳拟合直线），这个拟合过程就称作 回归。 利用 Logistic回归 进行分类的主要思想是：根据现有数据对分类边界线建立回归公式，以此进行分类。这里的“回归”一词源于最佳拟合，表示要找到 最佳拟合参数集，其背后的数学分析将在下一部分介绍。训练分类器时的做法就是寻找最佳拟合参数，使用的是最优化算法。 Logistic回归的一般过程 (1) 收集数据：采用任意方法收集数据。 (2) 准备数据：由于需要进行距离计算，因此要求数据类型为数值型。另外，结构化数据格式则最佳。 (3) 分析数据：采用任意方法对数据进行分析。 (4) 训练算法：大部分时间将用于训练，训练的目的是为了找到最佳的分类回归系数。 (5) 测试算法：一旦训练步骤完成，分类将会很快。 (6) 使用算法：首先，我们需要输入一些数据，并将其转换成对应的结构化数值；接着，基于训练好的回归系数就可以对这些数值进行简单的回归计算，判定它们属于哪个类别；在这之后，我们就可以在输出的类别上做一些其他分析工作。 优点：计算代价不高，易于理解和实现。 缺点：容易欠拟合，分类精度可能不高。 适用数据类型：数值型和标称型数据。 Logistic回归的因变量可以是二分类的，也可以是多分类的，但是实际中最为常用的就是二分类的Logistic回归。它利用的是Sigmoid函数阈值在[0,1]这个特性。Logistic回归进行分类的主要思想是：根据现有数据对分类边界线建立回归公式，以此进行分类。其实，Logistic本质上是一个基于条件概率的判别模型(Discriminative Model)。 Sigmoid 函数 σ(z)=11+e−z\\sigma \\left ( z \\right ) =\\frac{1}{1+e^{-z}} σ(z)=1+e−z1​ 因此，为了实现Logistic回归分类器，我们可以在每个特征上都乘以一个回归系数，然后把所有的结果值相加，将这个总和代入Sigmoid函数中，进而得到一个范围在0~1之间的数值。任何大于0.5的数据被分入1类，小于0.5即被归入0类。所以，Logistic回归也可以被看成是一种概率估计。 梯度上升算法 Sigmoid函数的输入记为zzz，由下面公式得出： z=w0x0+w1x1+w2x2+...+wnxnz=w_0x_0+w_1x_1+w_2x_2+...+w_nx_n z=w0​x0​+w1​x1​+w2​x2​+...+wn​xn​ 如果采用向量的写法，上述公式可以写成：z=wTxz=w^Txz=wTx,它表示将这两个数值向量对应元素相乘然后全部加起来即得到z值。其中的向量xxx是分类器的输入数据，向量www也就是我们要找到的最佳参数（系数），从而使得分类器尽可能地精确。为了寻找该最佳参数，需要用到最优化理论的一些知识。本文使用梯度上升算法进行求解。 梯度上升法基于的思想是：要找到某函数的最大值，最好的方法是沿着该函数的梯度方向探寻。如果梯度记为∇，则函数f(x,y)的梯度由下式表示： ▽f(x,y)=(∂f(x,y)∂x∂f(x,y)∂y)\\bigtriangledown f(x,y)=\\binom{\\frac{\\partial f(x,y)}{\\partial x} }{\\frac{\\partial f(x,y)}{\\partial y}} ▽f(x,y)=(∂y∂f(x,y)​∂x∂f(x,y)​​) 函数f (x,y)必须要在待计算的点上有定义并且可微。 上图中的梯度上升算法沿梯度方向移动了一步。可以看到，梯度算子总是指向函数值增长最快的方向。这里所说的是移动方向，而未提到移动量的大小。该量值称为步长，记做$\\alpha $。用向量来表示的话，梯度上升算法的迭代公式如下： w:=w+α▽wf(w)w:=w+\\alpha \\bigtriangledown _wf(w) w:=w+α▽w​f(w) 该公式将一直被迭代执行，直至达到某个停止条件为止，比如迭代次数达到某个指定值或算法达到某个可以允许的误差范围。 梯度下降算法 它与这里的梯度上升算法是一样的，只是公式中的加法需要变成减法。因此，对应的公式可以写成: w:=w−α▽wf(w)w:=w-\\alpha \\bigtriangledown _wf(w) w:=w−α▽w​f(w) 梯度上升算法用来求函数的最大值，而梯度下降算法用来求函数的最小值。 总结 Logistic回归的目的是寻找一个非线性函数Sigmoid的最佳拟合参数，求解过程可以由最优化算法来完成。在最优化算法中，最常用的就是 梯度上升算法，而 梯度上升算法 又可以简化为 随机梯度上升算法。 随机梯度上升算法与梯度上升算法的效果相当，但占用更少的计算资源。此外，随机梯度上升是一个在线算法，它可以在新数据到来时就完成参数更新，而不需要重新读取整个数据集来进行批处理运算。 当数据集较小时，使用梯度上升算法 当数据集较大时，使用改进的随机梯度上升算法 对应到Sklearn中，我们就可以根据数据情况选择优化算法，比如： 数据较小的时候，我们使用liblinear 数据较大时，我们使用sag和saga 支持向量机 支持向量机 优点：泛化错误率低，计算开销不大，结果易解释。 缺点：对参数调节和核函数的选择敏感，原始分类器不加修改仅适用于处理二类问题。 适用数据类型：数值型和标称型数据。 核心思想：基于最大间隔分隔数据 基本概念： 线性可分：可以很容易就在数据中给出一条直线将两组数据点分开。 分隔超平面：将数据集分割开来的直线。 间隔：离分隔超平面最近的点，到分隔面的距离。 支持向量：离分隔超平面最近的那些点。 寻找最大间隔 推导公式为：$\\left | W^TA+b \\right | /\\left | \\left | W \\right | \\right | $ 最大化间隔的目标就是找出分类器定义中的w和b。为此，我们必须找到具有最小间隔的数据点，而这些数据点也就是前面提到的支持向量。一旦找到具有最小间隔的数据点，我们就需要对该间隔最大化。这就可以写作： 直接求解上述问题相当困难，所以我们将它转换成为另一种更容易求解的形式。 约束条件为： SVM的一般流程 (1) 收集数据：可以使用任意方法。 (2) 准备数据：需要数值型数据。 (3) 分析数据：有助于可视化分隔超平面。 (4) 训练算法：SVM的大部分时间都源自训练，该过程主要实现两个参数的调优。 (5) 测试算法：十分简单的计算过程就可以实现。 (6) 使用算法：几乎所有分类问题都可以使用SVM，值得一提的是，SVM本身是一个二类分类器，对多类问题应用SVM需要对代码做一些修改。 使用SMO算法来实现SVM 在复杂数据上应用核函数 核函数的目的主要是为了解决非线性分类问题，通过核技巧将低维的非线性特征转化为高维的线性特征，从而可以通过线性模型来解决非线性的分类问题。 在图中，数据点处于一个圆中，人类的大脑能够意识到这一点。然而，对于分类器而言，它只能识别分类器的结果是大于0还是小于0。如果只在x和y轴构成的坐标系中插入直线进行分类的话，我们并不会得到理想的结果。但是或许可以对圆中的数据进行某种形式的转换，从而得到某些新的变量来表示数据。在这种表示情况下，我们就更容易得到大于0或者小于0的测试结果。在通常情况下，这种映射是通过 核函数 来实现的，会将低维特征空间映射到高维空间。 我们可以把核函数想象成一个 包装器（wrapper）或者是 接口（interface），它能把数据从某个很难处理的形式转换成为另一个较容易处理的形式。如果上述特征空间映射的说法听起来很让人迷糊的话，那么可以将它想象成为另外一种距离计算的方法。距离计算的方法有很多种，核函数一样具有多种类型。经过空间转换之后，我们可以在高维空间中解决线性问题，这也就等价于在低维空间中解决非线性问题。 总结 支持向量机是一种分类器。之所以称为“机”是因为它会产生一个二值决策结果，即它是一种决策“机”。支持向量机的泛化错误率较低，也就是说它具有良好的学习能力，且学到的结果具有很好的推广性。这些优点使得支持向量机十分流行，有些人认为它是监督学习中最好的定式算法。 支持向量机试图通过求解一个二次优化问题来最大化分类间隔。在过去，训练支持向量机常采用非常复杂并且低效的二次规划求解方法。John Platt引入了SMO算法，此算法可以通过每次只优化2个alpha值来加快SVM的训练速度。 核方法或者说核技巧会将数据（有时是非线性数据）从一个低维空间映射到一个高维空间，可以将一个在低维空间中的非线性问题转换成高维空间下的线性问题来求解。核方法不止在SVM中适用，还可以用于其他算法中。而其中的径向基函数是一个常用的度量两个向量距离的核函数。支持向量机是一个二类分类器。当用其解决多类问题时，则需要额外的方法对其进行扩展。SVM的效果也对优化参数和所用核函数中的参数敏感。 AdaBoost 元算法 基于数据集多重抽样的分类器 - 集成方法 集成方法（ensemble method） 通过组合多个学习器来完成学习任务，有点“三个臭皮匠顶个诸葛亮”的意味。基分类器一般采用的是 弱可学习（weakly learnable） 分类器，通过 集成方法，组合成一个 强可学习（strongly learnable） 分类器。弱可学习 是指学习的正确率仅略优于随机猜测的多项式学习算法；强可学习 指正确率较高的多项式学习算法。集成学习 的泛化能力一般比单一的基分类器要好，这是因为大部分基分类器都分类错误的概率远低于单一基分类器的。 集成方法 主要包括 Bagging 和 Boosting 两种方法，Bagging 和 Boosting 都是将已有的分类或回归算法通过一定方式组合起来，形成一个性能更加强大的分类器，更准确的说这是一种分类算法的组装方法，即将 弱分类器 组装成 强分类器 的方法。 bagging 自举汇聚法（bootstrap aggregating），也称为bagging方法，是在从原始数据集选择S次后得到S个新数据集的一种技术。新数据集和原数据集的大小相等。每个数据集都是通过在原始数据集中随机选择一个样本来进行替换而得到的。这里的替换就意味着可以多次地选择同一样本。这一性质就允许新数据集中可以有重复的值，而原始数据集的某些值在新集合中则不再出现。在S个数据集建好之后，将某个学习算法分别作用于每个数据集就得到了S个分类器。当要对新数据进行分类时，就可以应用这S个分类器进行分类。与此同时，选择分类器投票结果中最多的类别作为最后的分类结果。当然，还有一些更先进的bagging方法，比如 随机森林（random forest）。 Bagging 1.通过降低基分类器的方差，改善了泛化误差。 2.性能依赖于基分类器的稳定性，如果基分类器不稳定，bagging有助于降低训练数据的随机波动导致的误差；如果稳定，则集成分类器的误差主要由基分类器的偏倚引起。 3.由于每个样本被选中的概率相同，因此bagging并不侧重于训练数据集中的任何特定实例。 boosting boosting是一种与bagging很类似的技术。不论是在boosting还是bagging当中，所使用的多个分类器的类型都是一致的。但是在前者当中，不同的分类器是通过串行训练而获得的，每个新分类器都根据已训练出的分类器的性能来进行训练。 boosting是通过集中关注被已有分类器错分的那些数据来获得新的分类器。由于boosting分类的结果是基于所有分类器的加权求和结果的，因此boosting与bagging不太一样。bagging中的分类器权重是相等的，而boosting中的分类器权重并不相等，每个权重代表的是其对应分类器在上一轮迭代中的成功度。 二者的区别 样本选择上： Bagging：训练集是在原始集中有放回选取的，从原始集中选出的各轮训练集之间是独立的。 Boosting：每一轮的训练集不变，只是训练集中每个样例在分类器中的权重发生变化。而权值是根据上一轮的分类结果进行调整。 样例权重： Bagging：使用均匀取样，每个样例的权重相等。 Boosting：根据错误率不断调整样例的权值，错误率越大则权重越大。 预测函数： Bagging：所有预测函数的权重相等。 Boosting：每个弱分类器都有相应的权重，对于分类误差小的分类器会有更大的权重。 并行计算： Bagging：各个预测函数可以并行生成。 Boosting：各个预测函数只能顺序生成，因为后一个模型参数需要前一轮模型的结果。 AdaBoost—提升分类器性能利器 AdaBoost 优点：泛化错误率低，易编码，可以应用在大部分分类器上，无参数调整。 缺点：对离群点敏感。 适用数据类型：数值型和标称型数据。 AdaBoost的一般流程 (1) 收集数据：可以使用任意方法。 (2) 准备数据：依赖于所使用的弱分类器类型，本章使用的是单层决策树，这种分类器可以处理任何数据类型。当然也可以使用任意分类器作为弱分类器，第2章到第6章中的任一分类器都可以充当弱分类器。作为弱分类器，简单分类器的效果更好。 (3) 分析数据：可以使用任意方法。 (4) 训练算法：AdaBoost的大部分时间都用在训练上，分类器将多次在同一数据集上训练弱分类器。 (5) 测试算法：计算分类的错误率。 (6) 使用算法：同SVM一样，AdaBoost预测两个类别中的一个。如果想把它应用到多个类别的场合，那么就要像多类SVM中的做法一样对AdaBoost进行修改。 AdaBoost 是 adaptive boosting（自适应boosting） 的缩写，其运行过程如下：训练数据中的每个样本，并赋予其一个权重，这些权重构成了向量D。一开始，这些权重都初始化成相等值。首先在训练数据上训练出一个弱分类器并计算该分类器的错误率，然后在同一数据集上再次训练弱分类器。在分类器的第二次训练当中，将会重新调整每个样本的权重，其中 第一次分对的样本的权重将会降低，而第一次分错的样本的权重将会提高。为了从所有弱分类器中得到最终的分类结果，AdaBoost为每个分类器都分配了一个权重值alpha，这些alpha值是基于每个弱分类器的错误率进行计算的。其中，错误率ε的定义为： ε=未正确分类的样本数目所有样本数目\\varepsilon =\\frac{未正确分类的样本数目}{所有样本数目} ε=所有样本数目未正确分类的样本数目​ 而alpha的计算公式如下： α=12ln((1−εε)\\alpha =\\frac{1}{2}ln(\\frac{(1-\\varepsilon }{\\varepsilon } ) α=21​ln(ε(1−ε​) AdaBoost算法的流程如图所示。 计算出alpha值之后，可以对权重向量D进行更新，以使得那些正确分类的样本的权重降低而错分样本的权重升高。D的计算方法如下: 在计算出D之后，AdaBoost又开始进入下一轮迭代。AdaBoost算法会不断地重复训练和调整权重的过程，直到训练错误率为0或者弱分类器的数目达到用户的指定值为止。 AdaBoost算法总结如下： 分类器性能评估 在大多数情况下不同类别的分类代价并不相等，这就是非均衡分类问题。我们将会考察一种新的分类器性能度量方法，而不再是简单的通过错误率进行评价，并通过图像技术来对在上述非均衡问题下不同分类器的性能进行可视化处理。然后，考察这两种分类器的变换算法，它们能够将不同决策的代价考虑在内。 分类性能度量指标：正确率、召回率及ROC 曲线 到现在为止，都是基于错误率来衡量分类器任务的成功程度的。错误率指的是在所有测试样例中错分的样例比例。实际上，这样的度量错误掩盖了样例如何被分错的事实。在机器学习中，有一个普遍适用的称为 混淆矩阵（confusion matrix） 的工具，它可以帮助人们更好地了解分类中的错误。有这样一个关于在房子周围可能发现的动物类型的预测，这个预测的三类问题的混淆矩阵如表所示。 利用混淆矩阵就可以更好地理解分类中的错误了。如果矩阵中的非对角元素均为0，就会得到一个完美的分类器。 接下来，我们考虑另外一个混淆矩阵，这次的矩阵只针对一个简单的二类问题。在下表中，给出了该混淆矩阵。在这个二类问题中，如果将一个正例判为正例，那么就可以认为产生了一个 真正例（True Positive，TP，也称真阳）；如果对一个反例正确地判为反例，则认为产生了一个 真反例（True Negative，TN，也称真阴）。相应地，另外两种情况则分别称为 伪反例（False Negative，FN，也称假阴） 和 伪正例（False Positive，FP，也称假阳）。这4种情况如下表所示。 在分类中，当某个类别的重要性高于其他类别时，我们就可以利用上述定义来定义出多个比错误率更好的新指标。第一个指标是正确率（Precision），它等于TP/(TP+FP)，给出的是预测为正例的样本中的真正正例的比例。第二个指标是召回率（Recall），它等于TP/(TP+FN)，给出的是预测为正例的真实正例占所有真实正例的比例。在召回率很大的分类器中，真正判错的正例的数目并不多。 我们可以很容易构造一个高正确率或高召回率的分类器，但是很难同时保证两者成立。如果将任何样本都判为正例，那么召回率达到百分之百而此时正确率很低。构建一个同时使正确率和召回率最大的分类器是具有挑战性的。 另一个用于度量分类中的非均衡性的工具是 ROC曲线（ROC curve），ROC代表 接收者操作特征（receiver operating characteristic），它最早在二战期间由电气工程师构建雷达系统时使用过，如下图。 在ROC曲线中，给出了两条线，一条虚线一条实线。图中的横轴是伪正例的比例（假阳率=FP/(FP+TN)），而纵轴是真正例的比例（真阳率=TP/(TP+FN)）。ROC曲线给出的是当阈值变化时假阳率和真阳率的变化情况。左下角的点所对应的是将所有样例判为反例的情况，而右上角的点对应的则是将所有样例判为正例的情况。虚线给出的是随机猜测的结果曲线。 ROC曲线不但可以用于比较分类器，还可以基于 成本效益（cost-versus-benefit） 分析来做出决策。由于在不同的阈值下，不同的分类器的表现情况可能各不相同，因此以某种方式将它们组合起来或许会更有意义。如果只是简单地观察分类器的错误率，那么我们就难以得到这种更深入的洞察效果了。 在理想的情况下，最佳的分类器应该尽可能地处于左上角，这就意味着分类器在假阳率很低的同时获得了很高的真阳率。例如在垃圾邮件的过滤中，这就相当于过滤了所有的垃圾邮件，但没有将任何合法邮件误识为垃圾邮件而放入垃圾邮件的文件夹中。 对不同的ROC曲线进行比较的一个指标是 曲线下的面积（Area Unser the Curve，AUC）。AUC给出的是分类器的平均性能值，当然它并不能完全代替对整条曲线的观察。一个完美分类器的AUC为1.0，而随机猜测的AUC则为0.5。 基于代价函数的分类器决策控制 除了调节分类器的阈值之外，我们还有一些其他可以用于处理非均衡分类代价的方法，其中的一种称为 代价敏感的学习（cost-sensitive learning）。考虑表7-4中的代价矩阵，第一张表给出的是到目前为止分类器的代价矩阵（代价不是0就是1）。我们可以基于该代价矩阵计算其总代价：TP∗0+FN∗1+FP∗1+TN∗0TP*0+FN*1+FP*1+TN*0TP∗0+FN∗1+FP∗1+TN∗0 接下来我们考虑下面的第二张表，基于该代价矩阵的分类代价的计算公式为：TP∗(−5)+FN∗1+FP∗50+TN∗0TP*(-5)+FN*1+FP*50+TN*0TP∗(−5)+FN∗1+FP∗50+TN∗0。采用第二张表作为代价矩阵时，两种分类错误的代价是不一样的。类似地，这两种正确分类所得到的收益也不一样。如果在构建分类器时，知道了这些代价值，那么就可以选择付出最小代价的分类器。 在分类算法中，我们有很多方法可以用来引入代价信息。在AdaBoost中，可以基于代价函数来调整错误权重向量D。在朴素贝叶斯中，可以选择具有最小期望代价而不是最大概率的类别作为最后的结果。在SVM中，可以在代价函数中对于不同的类别选择不同的参数C。上述做法就会给较小类更多的权重，即在训练时，小类当中只允许更少的错误。 处理非均衡问题的数据抽样方法 另外一种针对非均衡问题调节分类器的方法，就是对分类器的训练数据进行改造。这可以通过**欠抽样（undersampling）或者过抽样（oversampling）**来实现。过抽样意味着复制样例，而欠抽样意味着删除样例。不管采用哪种方式，数据都会从原始形式改造为新形式。抽样过程则可以通过随机方式或者某个预定方式来实现。 通常也会存在某个罕见的类别需要我们来识别，比如在信用卡欺诈当中。如前所述，正例类别属于罕见类别。我们希望对于这种罕见类别能尽可能保留更多的信息，因此，我们应该保留正例类别中的所有样例，而对反例类别进行欠抽样或者样例删除处理。这种方法的一个缺点就在于要确定哪些样例需要进行剔除。但是，在选择剔除的样例中可能携带了剩余样例中并不包含的有价值信息。 上述问题的一种解决办法，就是选择那些离决策边界较远的样例进行删除。假定我们有一个数据集，其中有50例信用卡欺诈交易和5000例合法交易。如果我们想要对合法交易样例进行欠抽样处理，使得这两类数据比较均衡的话，那么我们就需要去掉4950个样例，而这些样例中可能包含很多有价值的信息。这看上去有些极端，因此有一种替代的策略就是使用反例类别的欠抽样和正例类别的过抽样相混合的方法。 要对正例类别进行过抽样，我们可以复制已有样例或者加入与已有样例相似的点。一种方法是加入已有数据点的插值点，但是这种做法可能会导致过拟合的问题。","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://yao-chen-ecnu.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://yao-chen-ecnu.github.io/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"BlueBerry投屏","slug":"BlueBerry投屏","date":"2021-03-16T02:06:42.711Z","updated":"2021-03-22T05:36:24.482Z","comments":true,"path":"2021/03/16/BlueBerry投屏/","link":"","permalink":"https://yao-chen-ecnu.github.io/2021/03/16/BlueBerry%E6%8A%95%E5%B1%8F/","excerpt":"","text":"BlueBerry投屏 使用方法 安装Windows接收端，解压安装包 如果电脑没用过平板投屏，先安装压缩包中的Bonjour64 打开blueberry，即双击打开压缩包中，可以在右下角任务栏中看到blueberry的图标 保证电脑和平板在同一局域网下，即连接同一个wifi 在ipad右上角触摸下拉唤醒控制中心，打开隔空投送并设置为所有人 打开屏幕镜像，选择blueberry 单击右下角菜单栏blueberry图标可以设置投屏形式","categories":[{"name":"工具使用","slug":"工具使用","permalink":"https://yao-chen-ecnu.github.io/categories/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/"}],"tags":[{"name":"投屏","slug":"投屏","permalink":"https://yao-chen-ecnu.github.io/tags/%E6%8A%95%E5%B1%8F/"}]},{"title":"如何优雅的使用LaTex打公式","slug":"如何优雅的使用LaTex打公式","date":"2021-03-16T02:06:42.707Z","updated":"2021-03-22T05:33:47.183Z","comments":true,"path":"2021/03/16/如何优雅的使用LaTex打公式/","link":"","permalink":"https://yao-chen-ecnu.github.io/2021/03/16/%E5%A6%82%E4%BD%95%E4%BC%98%E9%9B%85%E7%9A%84%E4%BD%BF%E7%94%A8LaTex%E6%89%93%E5%85%AC%E5%BC%8F/","excerpt":"","text":"如何优雅的使用LaTex打公式 推荐一个公式编辑网站：https://www.latexlive.com/ 网站支持公式的快捷编辑、图片识别公式并快速生成LaTex代码，公式可移植性强 输入区域 快捷工具：一些常用的符号、字母、公式形式（分数、根式、极限、积分）等 公式模板：提供一些常用的公式形式，代数、几何、积分、矩阵以及物理、化学等常用类别 图片识别：使用win自带截图，截好图之后，直接在提示区域内复制后就可识别并生成公式 输入区域的下方生成的是LaTex代码：可以直接复制使用到markdown文本中 输出区域是即时可见的公式，可以下载成图片形式或复制MathML形式的代码 在word中插入公式的方法 提前安装好MathType 按‘alt’和‘+’快捷键，即可进入公式输入框，可以使用latex语法写公式 选择 直接到公式输入框中粘贴 选择OK即可完成公式输入 在Typroa中插入公式的方法 打开Typora选择数学模块的三种方式 点击“段落”—&gt;“公式块” 快捷键Ctrl+Shift+m “$$”+回车 直接键入Tex代码 以上说的是行间公式的形式，默认是生成居中的代码块 生成行间公式的方法 在typora中设置内联公式：“文件”—“偏好设置”—“markdown”—“markdown扩展语法”—勾选”内联公式“ 在行内直接键入","categories":[{"name":"工具使用","slug":"工具使用","permalink":"https://yao-chen-ecnu.github.io/categories/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/"}],"tags":[{"name":"公式","slug":"公式","permalink":"https://yao-chen-ecnu.github.io/tags/%E5%85%AC%E5%BC%8F/"}]},{"title":"从僵尸游戏学Solidity","slug":"从僵尸游戏学Solidity（笔记）","date":"2021-03-15T12:45:57.437Z","updated":"2021-03-22T05:36:01.500Z","comments":true,"path":"2021/03/15/从僵尸游戏学Solidity（笔记）/","link":"","permalink":"https://yao-chen-ecnu.github.io/2021/03/15/%E4%BB%8E%E5%83%B5%E5%B0%B8%E6%B8%B8%E6%88%8F%E5%AD%A6Solidity%EF%BC%88%E7%AC%94%E8%AE%B0%EF%BC%89/","excerpt":"","text":"写在前面 学习地址：https://cryptozombies.io/zh/course 智能协议的永固性 （即以太坊上的 DApp 跟普通的应用程序的区别） 在你把智能协议传上以太坊之后，它就变得不可更改, 这种永固性意味着你的代码永远不能被调整或更新。你编译的程序会一直，永久的，不可更改的，存在以太坊上。这就是 Solidity 代码的安全性如此重要的一个原因。如果你的智能协议有任何漏洞，即使你发现了也无法补救。你只能让你的用户们放弃这个智能协议，然后转移到一个新的修复后的合约上。 但这恰好也是智能合约的一大优势。代码说明一切。如果你去读智能合约的代码，并验证它，你会发现，一旦函数被定义下来，每一次的运行，程序都会严格遵照函数中原有的代码逻辑一丝不苟地执行，完全不用担心函数被人篡改而得到意外的结果。 Gas - 驱动以太坊DApps的能源 在 Solidity 中，你的用户想要每次执行你的 DApp 都需要支付一定的 gas，gas 可以用以太币购买，因此，用户每次跑 DApp 都得花费以太币。 一个 DApp 收取多少 gas 取决于功能逻辑的复杂程度。每个操作背后，都在计算完成这个操作所需要的计算资源，（比如，存储数据就比做个加法运算贵得多）， 一次操作所需要花费的 gas 等于这个操作背后的所有运算花销的总和。 省 gas 的招数：结构封装 （Struct packing） 除了基本版的 uint 外，还有其他变种 uint：uint8，uint16，uint32等。 通常情况下我们不会考虑使用 uint 变种，因为无论如何定义 uint的大小，Solidity 为它保留256位的存储空间。例如，使用 uint8 而不是uint（uint256）不会为你节省任何 gas。 除非，把 uint 绑定到 struct 里面。 如果一个 struct 中有多个 uint，则尽可能使用较小的 uint, Solidity 会将这些 uint 打包在一起，从而占用较少的存储空间。 12345678910111213struct NormalStruct &#123; uint a; uint b; uint c;&#125;struct MiniMe &#123; uint32 a; uint32 b; uint c;&#125;&#x2F;&#x2F; 因为使用了结构打包，&#96;mini&#96; 比 &#96;normal&#96; 占用的空间更少NormalStruct normal &#x3D; NormalStruct(10, 20, 30);MiniMe mini &#x3D; MiniMe(10, 20, 30); “view” 函数不花 “gas” 这是因为 view 函数不会真正改变区块链上的任何数据 - 它们只是读取。因此用 view 标记一个函数，意味着告诉 web3.js，运行这个函数只需要查询你的本地以太坊节点，而不需要在区块链上创建一个事务（事务需要运行在每个节点上，因此花费 gas）。 注意：如果一个 view 函数在另一个函数的内部被调用，而调用函数与 view 函数的不属于同一个合约，也会产生调用成本。这是因为如果主调函数在以太坊创建了一个事务，它仍然需要逐个节点去验证。所以标记为 view 的函数只有在外部调用时才是免费的。 使用 SafeMath预防溢出 为了防止这些情况，OpenZeppelin 建立了一个叫做 SafeMath 的 库(library)，默认情况下可以防止这些问题。 一个_库_ 是 Solidity 中一种特殊的合约。其中一个有用的功能是给原始数据类型增加一些方法。 比如，使用 SafeMath 库的时候，我们将使用 using SafeMath for uint256 这样的语法。 SafeMath 库有四个方法 — add， sub， mul， 以及 div。现在我们可以这样来让 uint256 调用这些方法： 12345using SafeMath for uint256;uint256 a &#x3D; 5;uint256 b &#x3D; a.add(3); &#x2F;&#x2F; 5 + 3 &#x3D; 8uint256 c &#x3D; a.mul(2); &#x2F;&#x2F; 5 * 2 &#x3D; 10 Sodility 合约 一份合约就是以太应币应用的基本模块，所有的变量和函数都属于一份合约, 它是所有应用的起点. 版本指令：所有的 Solidity 源码都必须冠以*“version pragma”* — 标明 Solidity 编译器的版本. 以避免将来新的编译器可能破坏你的代码。（etc. pragma solidity ^0.4.19;) 123pragma solidity ^0.4.19;contract ZombieFactory &#123;&#125; OpenZeppelin库的Ownable 合约 1234567891011121314151617181920212223242526272829303132333435&#x2F;** * @title Ownable * @dev The Ownable contract has an owner address, and provides basic authorization control * functions, this simplifies the implementation of &quot;user permissions&quot;. *&#x2F;contract Ownable &#123; address public owner; event OwnershipTransferred(address indexed previousOwner, address indexed newOwner); &#x2F;** * @dev The Ownable constructor sets the original &#96;owner&#96; of the contract to the sender * account. *&#x2F; function Ownable() public &#123; owner &#x3D; msg.sender; &#125; &#x2F;** * @dev Throws if called by any account other than the owner. *&#x2F; modifier onlyOwner() &#123; require(msg.sender &#x3D;&#x3D; owner); _; &#125; &#x2F;** * @dev Allows the current owner to transfer control of the contract to a newOwner. * @param newOwner The address to transfer ownership to. *&#x2F; function transferOwnership(address newOwner) public onlyOwner &#123; require(newOwner !&#x3D; address(0)); OwnershipTransferred(owner, newOwner); owner &#x3D; newOwner; &#125;&#125; 1、构造函数：function Ownable()是一个 _ constructor_ (构造函数)，构造函数不是必须的，它与合约同名，构造函数一生中唯一的一次执行，就是在合约最初被创建的时候。 2、函数修饰符：modifier onlyOwner()。 修饰符跟函数很类似，不过是用来修饰其他已有函数用的， 在其他语句执行前，为它检查下先验条件。 在这个例子中，我们就可以写个修饰符 onlyOwner 检查下调用者，确保只有合约的主人才能运行本函数。 3、indexed 关键字： 数据类型 状态变量 状态变量是被永久地保存在合约中。也就是说它们被写入以太币区块链中. 想象成写入一个数据库。 无符号整数 uint 其值不能是负数，对于有符号的整数存在名为 int 的数据类型。注: Solidity中， uint 实际上是 uint256代名词， 一个256位的无符号整数。你也可以定义位数少的uints — uint8， uint16， uint32 12uint dnaDigits &#x3D; 16;uint dnaModulus &#x3D; 10 ** dnaDigits; 结构体 1234struct Person &#123; uint age; string name;&#125; 数组 Solidity 支持两种数组: 静态 数组和动态 数组 123456&#x2F;&#x2F; 固定长度为2的静态数组:uint[2] fixedArray;&#x2F;&#x2F; 固定长度为5的string类型的静态数组:string[5] stringArray;&#x2F;&#x2F; 动态数组，长度不固定，可以动态添加元素:uint[] dynamicArray; 也可以建立一个结构体类型的数组 12345678Person[] people; &#x2F;&#x2F; 这是动态数组，我们可以不断添加元素&#x2F;&#x2F; 创建一个新的Person:Person satoshi &#x3D; Person(172, &quot;Satoshi&quot;);&#x2F;&#x2F; 将新创建的satoshi添加进people数组:people.push(satoshi);&#x2F;&#x2F;也可以将两步合并people.push(Person(16, &quot;Vitalik&quot;));&#x2F;&#x2F;array.push() 在数组的尾部加入新元素，所以元素在数组中的顺序就是我们添加的顺序 注： 状态变量被永久保存在区块链中。所以在你的合约中创建动态数组来保存成结构的数据是非常有意义的。 公共数组 定义 public 数组, Solidity 会自动创建 getter 方法. 语法如下: 1Zombie[] public zombies; 其它的合约可以从这个数组读取数据（但不能写入数据），所以这在合约中是一个有用的保存公共数据的模式。 映射（Mapping）和地址（Address） Addresses（地址） 以太坊区块链由 _ account _ (账户)组成，一个帐户的余额是 以太 （在以太坊区块链上使用的币种），你可以和其他帐户之间支付和接受以太币，就像银行帐户可以电汇资金到其他银行帐户一样。 在 Solidity 中，有一些全局变量可以被所有函数调用。 其中一个就是 msg.sender，它指的是当前调用者（或智能合约）的 address。 Mapping（映射） 映射本质上是存储和查找数据所用的键-值对。 12mapping (uint &#x3D;&gt; address) public zombieToOwner;mapping (address &#x3D;&gt; uint) ownerZombieCount; Storage与Memory 在 Solidity 中，有两个地方可以存储变量 —— storage 或 memory。 Storage 变量是指永久存储在区块链中的变量。 Memory变量则是临时的，当外部函数对某合约调用完成时，内存型变量即被移除。 你可以把它想象成存储在你电脑的硬盘或是RAM中数据的关系。 默认情况下 Solidity 会自动处理它们。 状态变量（在函数之外声明的变量）默认为“存储”形式，并永久写入区块链；而在函数内部声明的变量是“内存”型的，它们函数调用结束后消失。 然而也有一些情况下，你需要手动声明存储类型，主要用于处理函数内的 _ 结构体 _ 和 _ 数组 _ 时 1234567891011121314151617181920212223Sandwich[] sandwiches;function eatSandwich(uint _index) public &#123; &#x2F;&#x2F; Sandwich mySandwich &#x3D; sandwiches[_index]; &#x2F;&#x2F; ^ 看上去很直接，不过 Solidity 将会给出警告 &#x2F;&#x2F; 告诉你应该明确在这里定义 &#96;storage&#96; 或者 &#96;memory&#96;。 &#x2F;&#x2F; 所以你应该明确定义 &#96;storage&#96;: Sandwich storage mySandwich &#x3D; sandwiches[_index]; &#x2F;&#x2F; ...这样 &#96;mySandwich&#96; 是指向 &#96;sandwiches[_index]&#96;的指针 &#x2F;&#x2F; 在存储里，另外... mySandwich.status &#x3D; &quot;Eaten!&quot;; &#x2F;&#x2F; ...这将永久把 &#96;sandwiches[_index]&#96; 变为区块链上的存储 &#x2F;&#x2F; 如果你只想要一个副本，可以使用&#96;memory&#96;: Sandwich memory anotherSandwich &#x3D; sandwiches[_index + 1]; &#x2F;&#x2F; ...这样 &#96;anotherSandwich&#96; 就仅仅是一个内存里的副本了 &#x2F;&#x2F; 另外 anotherSandwich.status &#x3D; &quot;Eaten!&quot;; &#x2F;&#x2F; ...将仅仅修改临时变量，对 &#96;sandwiches[_index + 1]&#96; 没有任何影响 &#x2F;&#x2F; 不过你可以这样做: sandwiches[_index + 1] &#x3D; anotherSandwich; &#x2F;&#x2F; ...如果你想把副本的改动保存回区块链存储&#125; Keccak256 和 类型转换 Ethereum 内部有一个散列函数keccak256，它用了SHA3版本。一个散列函数基本上就是把一个字符串转换为一个256位的16进制数字。字符串的一个微小变化会引起散列数据极大变化。 1uint rand &#x3D; uint(keccak256(_str)); 时间单位 变量 now 将返回当前的unix时间戳（自1970年1月1日以来经过的秒数）。 Solidity 还包含秒(seconds)，分钟(minutes)，小时(hours)，天(days)，周(weeks) 和 年(years) 等时间单位。它们都会转换成对应的秒数放入 uint 中。 123456789101112uint lastUpdated;&#x2F;&#x2F; 将‘上次更新时间’ 设置为 ‘现在’function updateTimestamp() public &#123; lastUpdated &#x3D; now;&#125;&#x2F;&#x2F; 如果到上次&#96;updateTimestamp&#96; 超过5分钟，返回 &#39;true&#39;&#x2F;&#x2F; 不到5分钟返回 &#39;false&#39;function fiveMinutesHavePassed() public view returns (bool) &#123; return (now &gt;&#x3D; (lastUpdated + 5 minutes));&#125; 函数 在 Solidity 中函数定义的句法如下: 12function createZombie(string _name, uint _dna) &#123; &#125; 注： 习惯上函数里的变量都是以(_)开头 (但不是硬性规定) 以区别全局变量。 require使得函数在执行过程中，当不满足某些条件时抛出错误，并停止执行。在调用一个函数之前，用 require 验证前置条件是非常有必要的。 1require(ownerZombieCount[msg.sender] &#x3D;&#x3D; 0); 公有/私有函数 Solidity 定义的函数的属性默认为公共。 这就意味着任何一方 (或其它合约) 都可以调用你合约里的函数。 将自己的函数定义为私有是一个好的编程习惯，只有当你需要外部世界调用它时才将它设置为公共。 123function _createZombie(string _name, uint _dna) private &#123; zombies.push(Zombie(_name, _dna)); &#125; 这意味着只有我们合约中的其它函数才能够调用这个函数,和函数的参数类似，私有函数的名字用(_)起始。 函数的修饰符 1、可见性修饰符:：决定函数何时和被谁调用：private 意味着它只能被合约内部调用； internal 就像 private 但是也能被继承的合约调用； external 只能从合约外部调用；最后 public 可以在任何地方调用，不管是内部还是外部。 2、状态修饰符：决定函数如何和区块链交互: view 告诉我们运行这个函数不会更改和保存任何数据； pure 告诉我们这个函数不但不会往区块链写数据，它甚至不从区块链读取数据。这两种在被从合约外部调用的时候都不花费任何gas（但是它们在被内部其他函数调用的时候将会耗费gas）。 123456&#x2F;&#x2F;viewfunction sayHello() public view returns (string) &#x2F;&#x2F;purefunction _multiply(uint a, uint b) private pure returns (uint) &#123; return a * b;&#125; 3、自定义的 modifier，我们可以自定义其对函数的约束逻辑。 1234567891011121314&#x2F;&#x2F; 存储用户年龄的映射mapping (uint &#x3D;&gt; uint) public age;&#x2F;&#x2F; 限定用户年龄的修饰符modifier olderThan(uint _age, uint _userId) &#123; require(age[_userId] &gt;&#x3D; _age); _;&#125;&#x2F;&#x2F; 必须年满16周岁才允许开车 (至少在美国是这样的).&#x2F;&#x2F; 我们可以用如下参数调用&#96;olderThan&#96; 修饰符:function driveCar(uint _userId) public olderThan(16, _userId) &#123; &#x2F;&#x2F; 其余的程序逻辑&#125; 4、payable 修饰符 payable方法是让 Solidity 和以太坊变得如此酷的一部分 —— 它们是一种可以接收以太的特殊函数。 12345678contract OnlineStore &#123; function buySomething() external payable &#123; &#x2F;&#x2F; 检查以确定0.001以太发送出去来运行函数: require(msg.value &#x3D;&#x3D; 0.001 ether); &#x2F;&#x2F; 如果为真，一些用来向函数调用者发送数字内容的逻辑 transferThing(msg.sender); &#125;&#125; 在这里，msg.value 是一种可以查看向合约发送了多少以太的方法，另外 ether 是一个內建单元。 这里发生的事是，一些人会从 web3.js 调用这个函数 (从DApp的前端)， 像这样 : 12&#x2F;&#x2F; 假设 &#96;OnlineStore&#96; 在以太坊上指向你的合约:OnlineStore.buySomething().send(from: web3.eth.defaultAccount, value: web3.utils.toWei(0.001)) 提现 12345contract GetPaid is Ownable &#123; function withdraw() external onlyOwner &#123; owner.transfer(this.balance); &#125;&#125; 通过 transfer 函数向一个地址发送以太， 然后 this.balance 将返回当前合约存储了多少以太。 返回值 单个返回值 123function _generateRandomDna(string _str) private returns (uint) &#123; &#x2F;&#x2F; 这里开始 &#125; 多个返回值 123456789101112131415161718function multipleReturns() internal returns(uint a, uint b, uint c) &#123; return (1, 2, 3);&#125;function processMultipleReturns() external &#123; uint a; uint b; uint c; &#x2F;&#x2F; 这样来做批量赋值: (a, b, c) &#x3D; multipleReturns();&#125;&#x2F;&#x2F; 或者如果我们只想返回其中一个变量:function getLastReturnValue() external &#123; uint c; &#x2F;&#x2F; 可以对其他字段留空: (,,c) &#x3D; multipleReturns();&#125; 继承（Inheritance）和引入（Import） 123import &quot;.&#x2F;zombiefactory.sol&quot;;contract ZombieFeeding is ZombieFactory &#123;&#125; 可以实现多继承 12contract ZombieOwnership is ZombieAttack, ERC721 &#123;&#125; For 循环 12345678910111213141516function getEvens() pure external returns(uint[]) &#123; uint[] memory evens &#x3D; new uint[](5); &#x2F;&#x2F; 在新数组中记录序列号 uint counter &#x3D; 0; &#x2F;&#x2F; 在循环从1迭代到10： for (uint i &#x3D; 1; i &lt;&#x3D; 10; i++) &#123; &#x2F;&#x2F; 如果 &#96;i&#96; 是偶数... if (i % 2 &#x3D;&#x3D; 0) &#123; &#x2F;&#x2F; 把它加入偶数数组 evens[counter] &#x3D; i; &#x2F;&#x2F;索引加一， 指向下一个空的‘even’ counter++; &#125; &#125; return evens;&#125; 事件 事件是合约和区块链通讯的一种机制。前端应用“监听”某些事件，并做出反应。 与其他合约的交互 如果我们的合约需要和区块链上的其他的合约会话，则需先定义一个 interface (接口)。 123456789101112131415contract KittyInterface &#123; function getKitty(uint256 _id) external view returns ( bool isGestating, bool isReady, uint256 cooldownIndex, uint256 nextActionAt, uint256 siringWithId, uint256 birthTime, uint256 matronId, uint256 sireId, uint256 generation, uint256 genes );&#125; 这个过程虽然看起来像在定义一个合约，但其实内里不同： 首先，我们只声明了要与之交互的函数 ，在其中我们没有使用到任何其他的函数或状态变量。 其次，我们并没有使用大括号（{ 和 }）定义函数体，我们单单用分号（;）结束了函数声明。这使它看起来像一个合约框架。 编译器就是靠这些特征认出它是一个接口的。 在我们的 app 代码中使用这个接口，合约就知道其他合约的函数是怎样的，应该如何调用，以及可期待什么类型的返回值。 只要将合约的可见性设置为public(公共)或external(外部)，它们就可以与以太坊区块链上的任何其他合约进行交互。 以太坊上的代币 一个 代币 在以太坊基本上就是一个遵循一些共同规则的智能合约——即它实现了所有其他代币合约共享的一组标准函数，例如 transfer(address _to, uint256 _value) 和 balanceOf(address _owner). 在智能合约内部，通常有一个映射， mapping(address =&gt; uint256) balances，用于追踪每个地址还有多少余额。所以基本上一个代币只是一个追踪谁拥有多少该代币的合约，和一些可以让那些用户将他们的代币转移到其他地址的函数。 代币标准：ERC20、ERC721（加密收藏品） ERC271代币是不能互换的，因为每个代币都被认为是唯一且不可分割的。 你只能以整个单位交易它们，并且每个单位都有唯一的 ID。 12345678910contract ERC721 &#123; event Transfer(address indexed _from, address indexed _to, uint256 _tokenId); event Approval(address indexed _owner, address indexed _approved, uint256 _tokenId); function balanceOf(address _owner) public view returns (uint256 _balance); function ownerOf(uint256 _tokenId) public view returns (address _owner); function transfer(address _to, uint256 _tokenId) public; function approve(address _to, uint256 _tokenId) public; function takeOwnership(uint256 _tokenId) public;&#125; ERC721: 转移标准 ERC721 规范有两种不同的方法来转移代币： 1234function transfer(address _to, uint256 _tokenId) public;function approve(address _to, uint256 _tokenId) public;function takeOwnership(uint256 _tokenId) public; 1、第一种方法是代币的拥有者调用transfer 方法，传入他想转移到的 address 和他想转移的代币的 _tokenId。 2、第二种方法是代币拥有者首先调用 approve，然后传入与以上相同的参数。接着，该合约会存储谁被允许提取代币，通常存储到一个 mapping (uint256 =&gt; address) 里。然后，当有人调用 takeOwnership 时，合约会检查 msg.sender 是否得到拥有者的批准来提取代币，如果是，则将代币转移给他。 123456789101112131415161718192021function _transfer(address _from, address _to, uint256 _tokenId) private &#123; ownerZombieCount[_to]++; ownerZombieCount[_from]--; zombieToOwner[_tokenId] &#x3D; _to; Transfer(_from, _to, _tokenId); &#125; function transfer(address _to, uint256 _tokenId) public onlyOwnerOf(_tokenId) &#123; _transfer(msg.sender, _to, _tokenId); &#125; function approve(address _to, uint256 _tokenId) public onlyOwnerOf(_tokenId) &#123; zombieApprovals[_tokenId] &#x3D; _to; Approval(msg.sender, _to, _tokenId); &#125; function takeOwnership(uint256 _tokenId) public &#123; require(zombieApprovals[_tokenId] &#x3D;&#x3D; msg.sender); address owner &#x3D; ownerOf(_tokenId); _transfer(owner, msg.sender, _tokenId); &#125; 应用前端和 Web3.js 什么是 Web3.js? 以太坊网络是由节点组成的，每一个节点都包含了区块链的一份拷贝。当你想要调用一份智能合约的一个方法，你需要从其中一个节点中查找并告诉它:智能合约的地址、你想调用的方法，以及你想传入那个方法的参数。以太坊节点只能识别一种叫做 JSON-RPC 的语言。这种语言直接读起来并不好懂。 幸运的是 Web3.js 把这些令人讨厌的查询语句都隐藏起来了， 所以你只需要与方便易懂的 JavaScript 界面进行交互即可。 12CryptoZombies.methods.createRandomZombie(&quot;Vitalik Nakamoto 🤔&quot;) .send(&#123; from: &quot;0xb60e8dd61c5d32be8058bb8eb970870f07233155&quot;, gas: &quot;3000000&quot; &#125;) 添加Web3.js工具 可以从 github 直接下载压缩后的 .js 文件 然后包含到项目文件中 1&lt;script language&#x3D;&quot;javascript&quot; type&#x3D;&quot;text&#x2F;javascript&quot; src&#x3D;&quot;web3.min.js&quot;&gt;&lt;&#x2F;script&gt; Web3 Provider 以太坊是由共享同一份数据的相同拷贝的 节点 构成的。 在 Web3.js 里设置 Web3 的 Provider（提供者） 告诉我们的代码应该和 哪个节点 交互来处理我们的读写。这就好像在传统的 Web 应用程序中为你的 API 调用设置远程 Web 服务器的网址。 Infura Infura 是一个服务，它维护了很多以太坊节点并提供了一个缓存层来实现高速读取。你可以用他们的 API 来免费访问这个服务。 用 Infura 作为节点提供者，你可以不用自己运营节点就能很可靠地向以太坊发送、接收信息。 你可以通过这样把 Infura 作为你的 Web3 节点提供者： 1var web3 &#x3D; new Web3(new Web3.providers.WebsocketProvider(&quot;wss:&#x2F;&#x2F;mainnet.infura.io&#x2F;ws&quot;)); Metamask Metamask 是 Chrome 和 Firefox 的浏览器扩展， 它能让用户安全地维护他们的以太坊账户和私钥， 并用他们的账户和使用 Web3.js 的网站互动。Metamask 默认使用 Infura 的服务器做为 web3 提供者。 使用 Metamask 的 web3 提供者 123456789101112131415window.addEventListener(&#39;load&#39;, function() &#123; &#x2F;&#x2F; 检查web3是否已经注入到(Mist&#x2F;MetaMask) if (typeof web3 !&#x3D;&#x3D; &#39;undefined&#39;) &#123; &#x2F;&#x2F; 使用 Mist&#x2F;MetaMask 的提供者 web3js &#x3D; new Web3(web3.currentProvider); &#125; else &#123; &#x2F;&#x2F; 处理用户没安装的情况， 比如显示一个消息 &#x2F;&#x2F; 告诉他们要安装 MetaMask 来使用我们的应用 &#125; &#x2F;&#x2F; 现在你可以启动你的应用并自由访问 Web3.js: startApp()&#125;) 与合约对话 Web3.js 需要两个东西来和你的合约对话: 它的地址和它的 ABI。 地址：在你部署智能合约以后，它将获得一个以太坊上的永久地址。 ABI当你编译你的合约向以太坊部署时(我们将在第七课详述)， Solidity 编译器会给你 ABI。将编译了的ABI 并放在名为cryptozombies_abi.js文件中，保存在一个名为 cryptoZombiesABI 的变量中。将cryptozombies_abi.js 包含进我们的项目，我们就能通过那个变量访问 CryptoZombies ABI 。 实例化 Web3.js 12&#x2F;&#x2F; 实例化 myContractvar myContract &#x3D; new web3js.eth.Contract(myABI, myContractAddress); 调用和合约函数 Web3.js 有两个方法来调用我们合约的函数: call and send. Call call 用来调用 view 和 pure 函数。它只运行在本地节点，不会在区块链上创建事务。（view 和 pure 函数是只读的并不会改变区块链的状态。它们也不会消耗任何gas。用户也不会被要求用MetaMask对事务签名。） 123456789function getZombieDetails(id) &#123; return cryptoZombies.methods.zombies(id).call()&#125;&#x2F;&#x2F; 调用函数并做一些其他事情getZombieDetails(15).then(function(result) &#123; console.log(&quot;Zombie 15: &quot; + JSON.stringify(result));&#125;); cryptoZombies.methods.zombies(id).call() 将和 Web3 提供者节点通信，告诉它返回从我们的合约中的 Zombie[] public zombies，id为传入参数的僵尸信息。 注意这是 异步的，就像从外部服务器中调用API。所以 Web3 在这里返回了一个 Promises. (如果你对 JavaScript的 Promises 不了解，最好先去学习一下这方面知识再继续)。 一旦那个 promise 被 resolve, (意味着我们从 Web3 提供者那里获得了响应)，我们的例子代码将执行 then 语句中的代码，在控制台打出 result。 获得 MetaMask中的用户账户 MetaMask 允许用户在扩展中管理多个账户。 我们可以通过这样来获取 web3 变量中激活的当前账户： 1var userAccount &#x3D; web3.eth.accounts[0] 因为用户可以随时在 MetaMask 中切换账户，我们的应用需要监控这个变量，一旦改变就要相应更新界面。例如，若用户的首页展示它们的僵尸大军，当他们在 MetaMask 中切换了账号，我们就需要更新页面来展示新选择的账户的僵尸大军。 我们可以通过 setInterval 方法来做: 123456789var accountInterval &#x3D; setInterval(function() &#123; &#x2F;&#x2F; Check if account has changed if (web3.eth.accounts[0] !&#x3D;&#x3D; userAccount) &#123; userAccount &#x3D; web3.eth.accounts[0]; &#x2F;&#x2F; Call a function to update the UI with the new account getZombiesByOwner(userAccount) .then(displayZombies); &#125; &#125;, 100); 这段代码做的是，每100毫秒检查一次 userAccount 是否还等于 web3.eth.accounts[0] (比如：用户是否还激活了那个账户)。若不等，则将 当前激活用户赋值给 userAccount，然后调用一个函数来更新界面。 Send send 将创建一个事务并改变区块链上的数据。你需要用 send 来调用任何非 view 或者 pure 的函数。（send 一个事务将要求用户支付gas，并会要求弹出对话框请求用户使用 Metamask 对事务签名。在我们使用 Metamask 作为我们的 web3 提供者的时候，所有这一切都会在我们调用 send() 的时候自动发生。而我们自己无需在代码中操心这一切。） 相对 call 函数，send 函数有如下主要区别: 1、send 一个事务需要一个 from 地址来表明谁在调用这个函数（也就是你 Solidity 代码里的 msg.sender )。 我们需要这是我们 DApp 的用户，这样一来 MetaMask 才会弹出提示让他们对事务签名。 2、send 一个事务将花费 gas 3、在用户 send 一个事务到该事务对区块链产生实际影响之间有一个不可忽略的延迟。这是因为我们必须等待事务被包含进一个区块里，以太坊上一个区块的时间平均下来是15秒左右。如果当前在以太坊上有大量挂起事务或者用户发送了过低的 gas 价格，我们的事务可能需要等待数个区块才能被包含进去，往往可能花费数分钟。 所以在我们的代码中我们需要编写逻辑来处理这部分异步特性。 1234567891011121314151617function createRandomZombie(name) &#123; &#x2F;&#x2F; 这将需要一段时间，所以在界面中告诉用户这一点 &#x2F;&#x2F; 事务被发送出去了 $(&quot;#txStatus&quot;).text(&quot;正在区块链上创建僵尸，这将需要一会儿...&quot;); &#x2F;&#x2F; 把事务发送到我们的合约: return cryptoZombies.methods.createRandomZombie(name) .send(&#123; from: userAccount &#125;) .on(&quot;receipt&quot;, function(receipt) &#123; $(&quot;#txStatus&quot;).text(&quot;成功生成了 &quot; + name + &quot;!&quot;); &#x2F;&#x2F; 事务被区块链接受了，重新渲染界面 getZombiesByOwner(userAccount).then(displayZombies); &#125;) .on(&quot;error&quot;, function(error) &#123; &#x2F;&#x2F; 告诉用户合约失败了 $(&quot;#txStatus&quot;).text(error); &#125;);&#125; Web3.js 中需要特殊对待的函数 — payable 函数。 123456789101112function levelUp(zombieId) &#123; $(&quot;#txStatus&quot;).text(&quot;Leveling up your zombie...&quot;); return cryptoZombies.methods.levelUp(zombieId) .send(&#123; from: userAccount, value: web3.utils.toWei(&quot;0.001&quot;, &quot;ether&quot;) &#125;) .on(&quot;receipt&quot;, function(receipt) &#123; $(&quot;#txStatus&quot;).text(&quot;Power overwhelming! Zombie successfully leveled up&quot;); &#125;) .on(&quot;error&quot;, function(error) &#123; $(&quot;#txStatus&quot;).text(error); &#125;); &#125; 订阅合约事件 在 Web3.js里， 你可以订阅 一个事件，这样你的 Web3 提供者可以在每次事件发生后触发你的一些代码逻辑： 12345cryptoZombies.events.NewZombie().on(&quot;data&quot;, function(event) &#123; let zombie &#x3D; event.returnValues; console.log(&quot;一个新僵尸诞生了！&quot;, zombie.zombieId, zombie.name, zombie.dna);&#125;).on(&#39;error&#39;, console.error); 注意这段代码将在 任何 僵尸生成的时候激发一个警告信息——而不仅仅是当前用用户的僵尸。如果我们只想对当前用户发出提醒呢？ 使用indexed 为了筛选仅和当前用户相关的事件，我们的 Solidity 合约将必须使用 indexed 关键字，就像我们在 ERC721 实现中的Transfer 事件中那样： 1event Transfer(address indexed _from, address indexed _to, uint256 _tokenId); 在这种情况下， 因为_from 和 _to 都是 indexed，这就意味着我们可以在前端事件监听中过滤事件 12345cryptoZombies.events.Transfer(&#123; filter: &#123; _to: userAccount &#125; &#125;).on(&quot;data&quot;, function(event) &#123; let data &#x3D; event.returnValues; &#x2F;&#x2F; 当前用户更新了一个僵尸！更新界面来显示&#125;).on(&#39;error&#39;, console.error); 查询过去的事件 我们甚至可以用 getPastEvents 查询过去的事件，并用过滤器 fromBlock 和 toBlock 给 Solidity 一个事件日志的时间范围(“block” 在这里代表以太坊区块编号）： 12345cryptoZombies.getPastEvents(&quot;NewZombie&quot;, &#123; fromBlock: 0, toBlock: &#39;latest&#39; &#125;).then(function(events) &#123; &#x2F;&#x2F; events 是可以用来遍历的 &#96;event&#96; 对象 &#x2F;&#x2F; 这段代码将返回给我们从开始以来创建的僵尸列表&#125;);","categories":[{"name":"区块链","slug":"区块链","permalink":"https://yao-chen-ecnu.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"}],"tags":[{"name":"Solidity","slug":"Solidity","permalink":"https://yao-chen-ecnu.github.io/tags/Solidity/"}]},{"title":"Hello World","slug":"hello-world","date":"2021-03-15T06:57:56.253Z","updated":"2021-03-15T06:57:56.253Z","comments":true,"path":"2021/03/15/hello-world/","link":"","permalink":"https://yao-chen-ecnu.github.io/2021/03/15/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick Start Create a new post 1$ hexo new &quot;My New Post&quot; More info: Writing Run server 1$ hexo server More info: Server Generate static files 1$ hexo generate More info: Generating Deploy to remote sites 1$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://yao-chen-ecnu.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"区块链+联邦学习论文阅读笔记","slug":"区块链-联邦学习论文阅读笔记","permalink":"https://yao-chen-ecnu.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE-%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"},{"name":"区块链","slug":"区块链","permalink":"https://yao-chen-ecnu.github.io/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"工具使用","slug":"工具使用","permalink":"https://yao-chen-ecnu.github.io/categories/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/"}],"tags":[{"name":"联邦学习","slug":"联邦学习","permalink":"https://yao-chen-ecnu.github.io/tags/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"},{"name":"区块链+联邦学习","slug":"区块链-联邦学习","permalink":"https://yao-chen-ecnu.github.io/tags/%E5%8C%BA%E5%9D%97%E9%93%BE-%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/"},{"name":"算法","slug":"算法","permalink":"https://yao-chen-ecnu.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"投屏","slug":"投屏","permalink":"https://yao-chen-ecnu.github.io/tags/%E6%8A%95%E5%B1%8F/"},{"name":"公式","slug":"公式","permalink":"https://yao-chen-ecnu.github.io/tags/%E5%85%AC%E5%BC%8F/"},{"name":"Solidity","slug":"Solidity","permalink":"https://yao-chen-ecnu.github.io/tags/Solidity/"}]}